cd /home/minshi/Pedestrian_Crossing_Intention_Prediction
================================================================================
🎯 训练和测试管道启动
================================================================================
配置文件: config_files/my/my_jaad.yaml
开始时间: 2025-11-12 04:53:04

🚀 开始训练...
2025-11-12 04:53:07.665902: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must
 be at least one NUMA node, so returning NUMA node zero                                                                                                             2025-11-12 04:53:07.670112: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must
 be at least one NUMA node, so returning NUMA node zero                                                                                                             2025-11-12 04:53:07.670358: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must
 be at least one NUMA node, so returning NUMA node zero                                                                                                             config_files/my/my_jaad.yaml
model_opts {'model': 'Transformer_depth', 'obs_input_type': ['box', 'depth', 'vehicle_speed', 'ped_speed'], 'enlarge_ratio': 1.5, 'obs_length': 16, 'time_to_event':
 [30, 60], 'overlap': 0.8, 'balance_data': False, 'apply_class_weights': True, 'dataset': 'jaad', 'normalize_boxes': True, 'generator': True, 'fusion_point': 'early', 'fusion_method': 'sum'}                                                                                                                                          data_opts {'fstride': 1, 'sample_type': 'beh', 'subset': 'default', 'data_split_type': 'default', 'seq_type': 'crossing', 'min_track_size': 76}
net_opts {'num_hidden_units': 256, 'global_pooling': 'avg', 'regularizer_val': 0.0001, 'cell_type': 'gru', 'backbone': 'vgg16', 'dropout': 0.1}
train_opts {'batch_size': 2, 'epochs': 30, 'lr': 5e-05, 'learning_scheduler': {}}
---------------------------------------------------------
Generating action sequence data
fstride: 1
sample_type: beh
subset: default
height_rng: [0, inf]
squarify_ratio: 0
data_split_type: default
seq_type: crossing
min_track_size: 76
random_params: {'ratios': None, 'val_data': True, 'regen_data': False}
kfold_params: {'num_folds': 5, 'fold': 1}
---------------------------------------------------------
Generating database for jaad
jaad database loaded from /home/minshi/Pedestrian_Crossing_Intention_Prediction/JAAD/data_cache/jaad_database.pkl
---------------------------------------------------------
Generating crossing data
Split: train
Number of pedestrians: 324 
Total number of samples: 194 
---------------------------------------------------------
Generating action sequence data
fstride: 1
sample_type: beh
subset: default
height_rng: [0, inf]
squarify_ratio: 0
data_split_type: default
seq_type: crossing
min_track_size: 76
random_params: {'ratios': None, 'val_data': True, 'regen_data': False}
kfold_params: {'num_folds': 5, 'fold': 1}
---------------------------------------------------------
Generating database for jaad
jaad database loaded from /home/minshi/Pedestrian_Crossing_Intention_Prediction/JAAD/data_cache/jaad_database.pkl
---------------------------------------------------------
Generating crossing data
Split: val
Number of pedestrians: 48 
Total number of samples: 22 
---------------------------------------------------------
Generating action sequence data
fstride: 1
sample_type: beh
subset: default
height_rng: [0, inf]
squarify_ratio: 0
data_split_type: default
seq_type: crossing
min_track_size: 76
random_params: {'ratios': None, 'val_data': True, 'regen_data': False}
kfold_params: {'num_folds': 5, 'fold': 1}
---------------------------------------------------------
Generating database for jaad
jaad database loaded from /home/minshi/Pedestrian_Crossing_Intention_Prediction/JAAD/data_cache/jaad_database.pkl
---------------------------------------------------------
Generating crossing data
Split: test
Number of pedestrians: 276 
Total number of samples: 171 
[DataGenerator] auto class_weight -> {0: 0.8247422680412371, 1: 0.17525773195876287}
[DataGenerator] auto class_weight -> {0: 0.7272727272727273, 1: 0.2727272727272727}
2025-11-12 04:53:09.913058: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN
) to use the following CPU instructions in performance-critical operations:  AVX2 FMA                                                                               To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12 04:53:09.913940: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must
 be at least one NUMA node, so returning NUMA node zero                                                                                                             2025-11-12 04:53:09.914112: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must
 be at least one NUMA node, so returning NUMA node zero                                                                                                             2025-11-12 04:53:09.914187: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must
 be at least one NUMA node, so returning NUMA node zero                                                                                                             2025-11-12 04:53:10.273173: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must
 be at least one NUMA node, so returning NUMA node zero                                                                                                             2025-11-12 04:53:10.273310: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must
 be at least one NUMA node, so returning NUMA node zero                                                                                                             2025-11-12 04:53:10.273398: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must
 be at least one NUMA node, so returning NUMA node zero                                                                                                             2025-11-12 04:53:10.273477: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3435 MB memory
:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9                                                        
============================================================
📊 MODEL PARAMETER STATISTICS
============================================================
Total parameters:        2,968,717
Trainable parameters:    2,968,711
Non-trainable parameters: 6
============================================================

/home/minshi/miniconda3/envs/tf26/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_ra
te` instead.                                                                                                                                                          warnings.warn(

🚀 Training started!
📁 Models will be saved to: data/models/jaad/Transformer_depth/12Nov2025-04h53m09s
📋 已复制 action_predict.py 到模型目录
2025-11-12 04:53:11.751994: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/30
2025-11-12 04:53:18.122894: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged
 once.                                                                                                                                                              2025-11-12 04:53:18.501864: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8100
1067/1067 [==============================] - 22s 14ms/step - loss: 9.4921 - cls_loss: 0.2126 - reg_loss: 0.0126 - intention_accuracy: 0.5220 - val_loss: 4.8436 - va
l_cls_loss: 0.2809 - val_reg_loss: 0.0016 - val_intention_accuracy: 0.3099                                                                                          /home/minshi/miniconda3/envs/tf26/lib/python3.8/site-packages/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must over
ride get_config. When loading, the custom mask layer must be passed to the custom_objects argument.                                                                   warnings.warn('Custom mask layers require a config and must override '
[Sigma] Epoch 1: sigma_cls=2.3174 sigma_reg=1.9606
Epoch 2/30
1067/1067 [==============================] - 15s 14ms/step - loss: 3.1911 - cls_loss: 0.1835 - reg_loss: 0.0030 - intention_accuracy: 0.6181 - val_loss: 2.2526 - va
l_cls_loss: 0.2845 - val_reg_loss: 0.0031 - val_intention_accuracy: 0.5826                                                                                          [Sigma] Epoch 2: sigma_cls=2.2633 sigma_reg=1.9064
Epoch 3/30
1067/1067 [==============================] - 17s 16ms/step - loss: 1.8989 - cls_loss: 0.1663 - reg_loss: 0.0022 - intention_accuracy: 0.6471 - val_loss: 1.7062 - va
l_cls_loss: 0.2661 - val_reg_loss: 0.0017 - val_intention_accuracy: 0.6405                                                                                          [Sigma] Epoch 3: sigma_cls=2.2090 sigma_reg=1.8519
Epoch 4/30
1067/1067 [==============================] - 24s 22ms/step - loss: 1.5784 - cls_loss: 0.1571 - reg_loss: 0.0021 - intention_accuracy: 0.6696 - val_loss: 1.5202 - va
l_cls_loss: 0.2676 - val_reg_loss: 0.0018 - val_intention_accuracy: 0.5992                                                                                          [Sigma] Epoch 4: sigma_cls=2.1546 sigma_reg=1.7972
Epoch 5/30
1067/1067 [==============================] - 24s 23ms/step - loss: 1.4394 - cls_loss: 0.1484 - reg_loss: 0.0021 - intention_accuracy: 0.6903 - val_loss: 1.4203 - va
l_cls_loss: 0.2776 - val_reg_loss: 0.0025 - val_intention_accuracy: 0.5909                                                                                          [Sigma] Epoch 5: sigma_cls=2.1002 sigma_reg=1.7425
Epoch 6/30
1067/1067 [==============================] - 25s 23ms/step - loss: 1.3494 - cls_loss: 0.1441 - reg_loss: 0.0022 - intention_accuracy: 0.7170 - val_loss: 1.3397 - va
l_cls_loss: 0.2630 - val_reg_loss: 0.0032 - val_intention_accuracy: 0.6116                                                                                          [Sigma] Epoch 6: sigma_cls=2.0458 sigma_reg=1.6876
Epoch 7/30
1067/1067 [==============================] - 25s 24ms/step - loss: 1.2750 - cls_loss: 0.1428 - reg_loss: 0.0021 - intention_accuracy: 0.6973 - val_loss: 1.2788 - va
l_cls_loss: 0.2957 - val_reg_loss: 0.0025 - val_intention_accuracy: 0.5992                                                                                          [Sigma] Epoch 7: sigma_cls=1.9915 sigma_reg=1.6327
Epoch 8/30
1067/1067 [==============================] - 25s 24ms/step - loss: 1.2043 - cls_loss: 0.1344 - reg_loss: 0.0022 - intention_accuracy: 0.7081 - val_loss: 1.2285 - va
l_cls_loss: 0.3496 - val_reg_loss: 0.0030 - val_intention_accuracy: 0.5785                                                                                          [Sigma] Epoch 8: sigma_cls=1.9371 sigma_reg=1.5778
Epoch 9/30
1067/1067 [==============================] - 25s 23ms/step - loss: 1.1359 - cls_loss: 0.1283 - reg_loss: 0.0021 - intention_accuracy: 0.7263 - val_loss: 1.1786 - va
l_cls_loss: 0.3970 - val_reg_loss: 0.0022 - val_intention_accuracy: 0.5744                                                                                          [Sigma] Epoch 9: sigma_cls=1.8826 sigma_reg=1.5227
Epoch 10/30
1067/1067 [==============================] - 25s 24ms/step - loss: 1.0675 - cls_loss: 0.1224 - reg_loss: 0.0019 - intention_accuracy: 0.7474 - val_loss: 1.1046 - va
l_cls_loss: 0.3565 - val_reg_loss: 0.0033 - val_intention_accuracy: 0.5702                                                                                          [Sigma] Epoch 10: sigma_cls=1.8280 sigma_reg=1.4676
Epoch 11/30
1067/1067 [==============================] - 25s 23ms/step - loss: 0.9983 - cls_loss: 0.1166 - reg_loss: 0.0019 - intention_accuracy: 0.7587 - val_loss: 1.0876 - va
l_cls_loss: 0.5061 - val_reg_loss: 0.0016 - val_intention_accuracy: 0.5413                                                                                          [Sigma] Epoch 11: sigma_cls=1.7735 sigma_reg=1.4125
Epoch 12/30
1067/1067 [==============================] - 25s 23ms/step - loss: 0.9270 - cls_loss: 0.1104 - reg_loss: 0.0018 - intention_accuracy: 0.7746 - val_loss: 1.0068 - va
l_cls_loss: 0.4496 - val_reg_loss: 0.0024 - val_intention_accuracy: 0.5289                                                                                          [Sigma] Epoch 12: sigma_cls=1.7190 sigma_reg=1.3573
Epoch 13/30
1067/1067 [==============================] - 24s 22ms/step - loss: 0.8552 - cls_loss: 0.1082 - reg_loss: 0.0019 - intention_accuracy: 0.7723 - val_loss: 0.9682 - va
l_cls_loss: 0.5205 - val_reg_loss: 0.0029 - val_intention_accuracy: 0.5372                                                                                          [Sigma] Epoch 13: sigma_cls=1.6645 sigma_reg=1.3020
Epoch 14/30
1067/1067 [==============================] - 24s 22ms/step - loss: 0.7793 - cls_loss: 0.1018 - reg_loss: 0.0018 - intention_accuracy: 0.7844 - val_loss: 0.8673 - va
l_cls_loss: 0.4266 - val_reg_loss: 0.0023 - val_intention_accuracy: 0.5124                                                                                          [Sigma] Epoch 14: sigma_cls=1.6099 sigma_reg=1.2466
Epoch 15/30
1067/1067 [==============================] - 25s 24ms/step - loss: 0.7037 - cls_loss: 0.1036 - reg_loss: 0.0017 - intention_accuracy: 0.7793 - val_loss: 0.8028 - va
l_cls_loss: 0.4369 - val_reg_loss: 0.0022 - val_intention_accuracy: 0.5620                                                                                          [Sigma] Epoch 15: sigma_cls=1.5555 sigma_reg=1.1912
Epoch 16/30
1067/1067 [==============================] - 25s 23ms/step - loss: 0.6206 - cls_loss: 0.0934 - reg_loss: 0.0018 - intention_accuracy: 0.7891 - val_loss: 0.7822 - va
l_cls_loss: 0.5488 - val_reg_loss: 0.0016 - val_intention_accuracy: 0.5992                                                                                          [Sigma] Epoch 16: sigma_cls=1.5007 sigma_reg=1.1356
Epoch 17/30
1067/1067 [==============================] - 25s 23ms/step - loss: 0.5376 - cls_loss: 0.0926 - reg_loss: 0.0016 - intention_accuracy: 0.8069 - val_loss: 0.6572 - va
l_cls_loss: 0.4315 - val_reg_loss: 0.0018 - val_intention_accuracy: 0.5909                                                                                          [Sigma] Epoch 17: sigma_cls=1.4462 sigma_reg=1.0799
Epoch 18/30
1067/1067 [==============================] - 25s 23ms/step - loss: 0.4501 - cls_loss: 0.0896 - reg_loss: 0.0016 - intention_accuracy: 0.8177 - val_loss: 0.6034 - va
l_cls_loss: 0.4725 - val_reg_loss: 0.0017 - val_intention_accuracy: 0.5992                                                                                          [Sigma] Epoch 18: sigma_cls=1.3917 sigma_reg=1.0241
Epoch 19/30
1067/1067 [==============================] - 25s 24ms/step - loss: 0.3595 - cls_loss: 0.0883 - reg_loss: 0.0015 - intention_accuracy: 0.8187 - val_loss: 0.5728 - va
l_cls_loss: 0.5537 - val_reg_loss: 0.0015 - val_intention_accuracy: 0.6281                                                                                          [Sigma] Epoch 19: sigma_cls=1.3372 sigma_reg=0.9682
Epoch 20/30
1067/1067 [==============================] - 25s 24ms/step - loss: 0.2643 - cls_loss: 0.0877 - reg_loss: 0.0015 - intention_accuracy: 0.8336 - val_loss: 0.5882 - va
l_cls_loss: 0.7019 - val_reg_loss: 0.0011 - val_intention_accuracy: 0.6488                                                                                          [Sigma] Epoch 20: sigma_cls=1.2829 sigma_reg=0.9121
Epoch 21/30
1067/1067 [==============================] - 25s 23ms/step - loss: 0.1607 - cls_loss: 0.0797 - reg_loss: 0.0015 - intention_accuracy: 0.8510 - val_loss: 0.3511 - va
l_cls_loss: 0.4463 - val_reg_loss: 0.0012 - val_intention_accuracy: 0.6612                                                                                          [Sigma] Epoch 21: sigma_cls=1.2285 sigma_reg=0.8559
Epoch 22/30
1067/1067 [==============================] - 24s 23ms/step - loss: 0.0547 - cls_loss: 0.0795 - reg_loss: 0.0014 - intention_accuracy: 0.8515 - val_loss: 0.2545 - va
l_cls_loss: 0.4295 - val_reg_loss: 0.0017 - val_intention_accuracy: 0.6157                                                                                          [Sigma] Epoch 22: sigma_cls=1.1745 sigma_reg=0.7994
Epoch 23/30
1067/1067 [==============================] - 23s 22ms/step - loss: -0.0571 - cls_loss: 0.0777 - reg_loss: 0.0015 - intention_accuracy: 0.8515 - val_loss: 0.3182 - v
al_cls_loss: 0.6221 - val_reg_loss: 0.0015 - val_intention_accuracy: 0.6488                                                                                         [Sigma] Epoch 23: sigma_cls=1.1204 sigma_reg=0.7428
Epoch 24/30
1067/1067 [==============================] - 24s 22ms/step - loss: -0.1760 - cls_loss: 0.0775 - reg_loss: 0.0014 - intention_accuracy: 0.8618 - val_loss: 0.3050 - v
al_cls_loss: 0.6956 - val_reg_loss: 0.0013 - val_intention_accuracy: 0.6405                                                                                         [Sigma] Epoch 24: sigma_cls=1.0669 sigma_reg=0.6859
Epoch 25/30
1067/1067 [==============================] - 25s 23ms/step - loss: -0.3084 - cls_loss: 0.0708 - reg_loss: 0.0014 - intention_accuracy: 0.8594 - val_loss: 0.0985 - v
al_cls_loss: 0.5560 - val_reg_loss: 0.0016 - val_intention_accuracy: 0.6116                                                                                         [Sigma] Epoch 25: sigma_cls=1.0133 sigma_reg=0.6287
Epoch 26/30
1067/1067 [==============================] - 25s 23ms/step - loss: -0.4381 - cls_loss: 0.0760 - reg_loss: 0.0014 - intention_accuracy: 0.8655 - val_loss: -0.0523 - 
val_cls_loss: 0.4988 - val_reg_loss: 0.0013 - val_intention_accuracy: 0.6570                                                                                        [Sigma] Epoch 26: sigma_cls=0.9606 sigma_reg=0.5712
Epoch 27/30
1067/1067 [==============================] - 24s 23ms/step - loss: -0.5984 - cls_loss: 0.0648 - reg_loss: 0.0013 - intention_accuracy: 0.8749 - val_loss: 0.0353 - v
al_cls_loss: 0.6506 - val_reg_loss: 0.0014 - val_intention_accuracy: 0.6777                                                                                         [Sigma] Epoch 27: sigma_cls=0.9073 sigma_reg=0.5133
Epoch 28/30
1067/1067 [==============================] - 24s 22ms/step - loss: -0.7457 - cls_loss: 0.0739 - reg_loss: 0.0013 - intention_accuracy: 0.8571 - val_loss: -0.0502 - 
val_cls_loss: 0.6467 - val_reg_loss: 8.5120e-04 - val_intention_accuracy: 0.6818                                                                                    [Sigma] Epoch 28: sigma_cls=0.8559 sigma_reg=0.4548
Epoch 29/30
1067/1067 [==============================] - 24s 22ms/step - loss: -0.9270 - cls_loss: 0.0711 - reg_loss: 0.0012 - intention_accuracy: 0.8585 - val_loss: 0.1018 - v
al_cls_loss: 0.7996 - val_reg_loss: 0.0010 - val_intention_accuracy: 0.5992                                                                                         [Sigma] Epoch 29: sigma_cls=0.8044 sigma_reg=0.3957
Epoch 30/30
1067/1067 [==============================] - 24s 22ms/step - loss: -1.1375 - cls_loss: 0.0641 - reg_loss: 0.0011 - intention_accuracy: 0.8824 - val_loss: 0.0362 - v
al_cls_loss: 0.7923 - val_reg_loss: 0.0013 - val_intention_accuracy: 0.6322                                                                                         [Sigma] Epoch 30: sigma_cls=0.7543 sigma_reg=0.3357

🎯 Training completed!
📁 All epoch models saved in: data/models/jaad/Transformer_depth/12Nov2025-04h53m09s/epochs
Train model is saved to data/models/jaad/Transformer_depth/12Nov2025-04h53m09s/model.h5
Available metrics: ['loss', 'cls_loss', 'reg_loss', 'intention_accuracy', 'val_loss', 'val_cls_loss', 'val_reg_loss', 'val_intention_accuracy', 'sigma_cls', 'val_si
gma_cls', 'sigma_reg', 'val_sigma_reg']                                                                                                                             Training plots saved to model directory
Wrote configs to data/models/jaad/Transformer_depth/12Nov2025-04h53m09s/configs.yaml
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 21s 10ms/step

======================================================================
🎯 MODEL TEST RESULTS 🎯
======================================================================
Accuracy:   0.6364
AUC:        0.6061
F1-Score:   0.7143
Precision:  0.7025
Recall:     0.7264
======================================================================

Model saved to data/models/jaad/Transformer_depth/12Nov2025-04h53m09s/

✅ 训练完成 (耗时: 12.7 分钟)
🔍 查找最新模型目录...
📁 找到模型目录: data/models/jaad/Transformer_depth/12Nov2025-04h53m09s

🧪 开始测试模型...
2025-11-12 05:05:53.007977: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must
 be at least one NUMA node, so returning NUMA node zero                                                                                                             2025-11-12 05:05:53.014567: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must
 be at least one NUMA node, so returning NUMA node zero                                                                                                             2025-11-12 05:05:53.014770: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must
 be at least one NUMA node, so returning NUMA node zero                                                                                                             🚀 开始测试模型目录: data/models/jaad/Transformer_depth/12Nov2025-04h53m09s
✅ 配置文件加载成功
✅ 数据集初始化成功
🔄 生成测试数据...
---------------------------------------------------------
Generating action sequence data
fstride: 1
sample_type: beh
subset: default
height_rng: [0, inf]
squarify_ratio: 0
data_split_type: default
seq_type: crossing
min_track_size: 76
random_params: {'ratios': None, 'val_data': True, 'regen_data': False}
kfold_params: {'num_folds': 5, 'fold': 1}
---------------------------------------------------------
Generating database for jaad
jaad database loaded from /home/minshi/Pedestrian_Crossing_Intention_Prediction/JAAD/data_cache/jaad_database.pkl
---------------------------------------------------------
Generating crossing data
Split: test
Number of pedestrians: 276 
Total number of samples: 171 
✅ 测试数据生成完成
📁 找到 31 个模型文件

============================================================
进度: 1/31

🔍 测试模型: epoch_001_loss_4.8436_acc_0.3099.h5
2025-11-12 05:05:54.537718: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN
) to use the following CPU instructions in performance-critical operations:  AVX2 FMA                                                                               To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12 05:05:54.540138: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must
 be at least one NUMA node, so returning NUMA node zero                                                                                                             2025-11-12 05:05:54.540371: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must
 be at least one NUMA node, so returning NUMA node zero                                                                                                             2025-11-12 05:05:54.540509: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must
 be at least one NUMA node, so returning NUMA node zero                                                                                                             2025-11-12 05:05:55.072381: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must
 be at least one NUMA node, so returning NUMA node zero                                                                                                             2025-11-12 05:05:55.072594: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must
 be at least one NUMA node, so returning NUMA node zero                                                                                                             2025-11-12 05:05:55.072734: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must
 be at least one NUMA node, so returning NUMA node zero                                                                                                             2025-11-12 05:05:55.072858: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3953 MB memory
:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9                                                        [DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
2025-11-12 05:05:56.932818: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)
2025-11-12 05:05:58.856584: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged
 once.                                                                                                                                                              2025-11-12 05:05:59.467356: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8100
1881/1881 [==============================] - 21s 10ms/step
✅ 准确率: 0.4290, AUC: 0.6699, F1: 0.1674

============================================================
进度: 2/31

🔍 测试模型: epoch_002_loss_2.2526_acc_0.5826.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 20s 10ms/step
✅ 准确率: 0.6566, AUC: 0.7353, F1: 0.6704

============================================================
进度: 3/31

🔍 测试模型: epoch_003_loss_1.7062_acc_0.6405.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 20s 10ms/step
✅ 准确率: 0.6725, AUC: 0.7144, F1: 0.7303

============================================================
进度: 4/31

🔍 测试模型: epoch_004_loss_1.5202_acc_0.5992.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 20s 10ms/step
✅ 准确率: 0.6539, AUC: 0.7152, F1: 0.6841

============================================================
进度: 5/31

🔍 测试模型: epoch_005_loss_1.4203_acc_0.5909.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 20s 10ms/step
✅ 准确率: 0.6544, AUC: 0.7282, F1: 0.6839

============================================================
进度: 6/31

🔍 测试模型: epoch_006_loss_1.3397_acc_0.6116.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 21s 11ms/step
✅ 准确率: 0.6555, AUC: 0.7181, F1: 0.6900

============================================================
进度: 7/31

🔍 测试模型: epoch_007_loss_1.2788_acc_0.5992.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 20s 10ms/step
✅ 准确率: 0.6534, AUC: 0.7235, F1: 0.6925

============================================================
进度: 8/31

🔍 测试模型: epoch_008_loss_1.2285_acc_0.5785.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 20s 10ms/step
✅ 准确率: 0.6677, AUC: 0.7145, F1: 0.7097

============================================================
进度: 9/31

🔍 测试模型: epoch_009_loss_1.1786_acc_0.5744.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 21s 10ms/step
✅ 准确率: 0.6619, AUC: 0.7120, F1: 0.7117

============================================================
进度: 10/31

🔍 测试模型: epoch_010_loss_1.1046_acc_0.5702.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 20s 10ms/step
✅ 准确率: 0.6752, AUC: 0.7153, F1: 0.7266

============================================================
进度: 11/31

🔍 测试模型: epoch_011_loss_1.0876_acc_0.5413.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 15s 8ms/step
✅ 准确率: 0.6885, AUC: 0.7300, F1: 0.7423

============================================================
进度: 12/31

🔍 测试模型: epoch_012_loss_1.0068_acc_0.5289.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 12s 6ms/step
✅ 准确率: 0.6715, AUC: 0.7086, F1: 0.7270

============================================================
进度: 13/31

🔍 测试模型: epoch_013_loss_0.9682_acc_0.5372.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 13s 6ms/step
✅ 准确率: 0.6624, AUC: 0.7092, F1: 0.7138

============================================================
进度: 14/31

🔍 测试模型: epoch_014_loss_0.8673_acc_0.5124.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 16s 8ms/step
✅ 准确率: 0.6443, AUC: 0.6776, F1: 0.7072

============================================================
进度: 15/31

🔍 测试模型: epoch_015_loss_0.8028_acc_0.5620.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 20s 10ms/step
✅ 准确率: 0.6316, AUC: 0.6895, F1: 0.6751

============================================================
进度: 16/31

🔍 测试模型: epoch_016_loss_0.7822_acc_0.5992.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 21s 10ms/step
✅ 准确率: 0.6502, AUC: 0.6808, F1: 0.7193

============================================================
进度: 17/31

🔍 测试模型: epoch_017_loss_0.6572_acc_0.5909.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 20s 10ms/step
✅ 准确率: 0.6273, AUC: 0.6533, F1: 0.7126

============================================================
进度: 18/31

🔍 测试模型: epoch_018_loss_0.6034_acc_0.5992.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 20s 10ms/step
✅ 准确率: 0.6023, AUC: 0.6374, F1: 0.7015

============================================================
进度: 19/31

🔍 测试模型: epoch_019_loss_0.5728_acc_0.6281.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 20s 10ms/step
✅ 准确率: 0.6209, AUC: 0.6767, F1: 0.7108

============================================================
进度: 20/31

🔍 测试模型: epoch_020_loss_0.5882_acc_0.6488.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 20s 10ms/step
✅ 准确率: 0.6534, AUC: 0.6906, F1: 0.7465

============================================================
进度: 21/31

🔍 测试模型: epoch_021_loss_0.3511_acc_0.6612.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 11s 6ms/step
✅ 准确率: 0.6295, AUC: 0.6755, F1: 0.7075

============================================================
进度: 22/31

🔍 测试模型: epoch_022_loss_0.2545_acc_0.6157.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 11s 6ms/step
✅ 准确率: 0.6268, AUC: 0.6795, F1: 0.7005

============================================================
进度: 23/31

🔍 测试模型: epoch_023_loss_0.3182_acc_0.6488.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 12s 6ms/step
✅ 准确率: 0.6380, AUC: 0.6856, F1: 0.7292

============================================================
进度: 24/31

🔍 测试模型: epoch_024_loss_0.3050_acc_0.6405.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 17s 8ms/step
✅ 准确率: 0.6295, AUC: 0.6939, F1: 0.7266

============================================================
进度: 25/31

🔍 测试模型: epoch_025_loss_0.0985_acc_0.6116.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 20s 10ms/step
✅ 准确率: 0.6220, AUC: 0.6773, F1: 0.6913

============================================================
进度: 26/31

🔍 测试模型: epoch_026_loss_-0.0523_acc_0.6570.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 20s 10ms/step
✅ 准确率: 0.6427, AUC: 0.6871, F1: 0.7188

============================================================
进度: 27/31

🔍 测试模型: epoch_027_loss_0.0353_acc_0.6777.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 21s 10ms/step
✅ 准确率: 0.6178, AUC: 0.6802, F1: 0.7275

============================================================
进度: 28/31

🔍 测试模型: epoch_028_loss_-0.0502_acc_0.6818.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 20s 10ms/step
✅ 准确率: 0.6082, AUC: 0.6599, F1: 0.7279

============================================================
进度: 29/31

🔍 测试模型: epoch_029_loss_0.1018_acc_0.5992.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 20s 10ms/step
✅ 准确率: 0.6199, AUC: 0.6630, F1: 0.7080

============================================================
进度: 30/31

🔍 测试模型: epoch_030_loss_0.0362_acc_0.6322.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 21s 11ms/step
✅ 准确率: 0.6364, AUC: 0.6711, F1: 0.7143

============================================================
进度: 31/31

🔍 测试模型: model.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 19s 10ms/step
✅ 准确率: 0.6364, AUC: 0.6711, F1: 0.7143

📊 结果已保存到: data/models/jaad/Transformer_depth/12Nov2025-04h53m09s/test_results_20251112_051622.csv
📝 报告已保存到: data/models/jaad/Transformer_depth/12Nov2025-04h53m09s/test_report_20251112_051622.txt

🏆 准确率最高的模型: epoch_011_loss_1.0876_acc_0.5413.h5 (准确率: 0.6885)
🗑️  开始清理epochs目录，将删除 30 个模型文件...
🗑️  已删除: epoch_006_loss_1.3397_acc_0.6116.h5
🗑️  已删除: epoch_004_loss_1.5202_acc_0.5992.h5
🗑️  已删除: epoch_001_loss_4.8436_acc_0.3099.h5
🗑️  已删除: epoch_005_loss_1.4203_acc_0.5909.h5
🗑️  已删除: epoch_008_loss_1.2285_acc_0.5785.h5
🗑️  已删除: epoch_029_loss_0.1018_acc_0.5992.h5
🗑️  已删除: epoch_013_loss_0.9682_acc_0.5372.h5
🗑️  已删除: epoch_012_loss_1.0068_acc_0.5289.h5
🗑️  已删除: epoch_022_loss_0.2545_acc_0.6157.h5
🗑️  已删除: epoch_020_loss_0.5882_acc_0.6488.h5
🗑️  已删除: epoch_026_loss_-0.0523_acc_0.6570.h5
🗑️  已删除: epoch_015_loss_0.8028_acc_0.5620.h5
🗑️  已删除: epoch_002_loss_2.2526_acc_0.5826.h5
🗑️  已删除: epoch_023_loss_0.3182_acc_0.6488.h5
🗑️  已删除: epoch_024_loss_0.3050_acc_0.6405.h5
🗑️  已删除: epoch_003_loss_1.7062_acc_0.6405.h5
🗑️  已删除: epoch_030_loss_0.0362_acc_0.6322.h5
🗑️  已删除: epoch_016_loss_0.7822_acc_0.5992.h5
🗑️  已删除: epoch_018_loss_0.6034_acc_0.5992.h5
📋 已将最佳模型复制到: data/models/jaad/Transformer_depth/12Nov2025-04h53m09s/epoch_011_loss_1.0876_acc_0.5413.h5
🗑️  已删除: epoch_011_loss_1.0876_acc_0.5413.h5
🗑️  已删除: epoch_017_loss_0.6572_acc_0.5909.h5
🗑️  已删除: epoch_014_loss_0.8673_acc_0.5124.h5
🗑️  已删除: epoch_010_loss_1.1046_acc_0.5702.h5
🗑️  已删除: epoch_025_loss_0.0985_acc_0.6116.h5
🗑️  已删除: epoch_021_loss_0.3511_acc_0.6612.h5
🗑️  已删除: epoch_009_loss_1.1786_acc_0.5744.h5
🗑️  已删除: epoch_028_loss_-0.0502_acc_0.6818.h5
🗑️  已删除: epoch_007_loss_1.2788_acc_0.5992.h5
🗑️  已删除: epoch_027_loss_0.0353_acc_0.6777.h5
🗑️  已删除: epoch_019_loss_0.5728_acc_0.6281.h5
🗑️  已删除空的epochs目录
🔄 模型目录已重命名:
   原目录: 12Nov2025-04h53m09s
   新目录: 12Nov2025-04h53m09s_acc_0.6885

================================================================================
🎯 测试结果汇总
================================================================================
总模型数量: 31
成功测试: 31
失败测试: 0

📊 性能统计:
平均准确率: 0.6368 (±0.0438)
平均AUC: 0.6918 (±0.0248)
平均F1: 0.6932 (±0.0993)

🏆 最佳模型:
最高准确率: epoch_011_loss_1.0876_acc_0.5413.h5 (Acc: 0.6885)
最高AUC: epoch_002_loss_2.2526_acc_0.5826.h5 (AUC: 0.7353)
最高F1: epoch_020_loss_0.5882_acc_0.6488.h5 (F1: 0.7465)

✅ 测试完成 (耗时: 10.6 分钟)

================================================================================
🎉 训练和测试管道完成!
================================================================================
模型目录: data/models/jaad/Transformer_depth/12Nov2025-04h53m09s
总耗时: 23.3 分钟
结束时间: 2025-11-12 05:16:24
================================================================================
