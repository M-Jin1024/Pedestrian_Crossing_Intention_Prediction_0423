 cd /home/minshi/Pedestrian_Crossing_Intention_Prediction ; /usr/bin/env /home/minshi/miniconda3/envs/tf26/bin/python /home/minshi/.vscode/extensions/ms-python.debugpy-2025.14.1-linux-x64/bundled/libs/debugpy/adapter/../../debugpy/launcher 43375 -- /home/minshi/Pedestrian_Crossing_Intention_Prediction/train_and_test_all_epoch_pipeline.py -c config_files/my/my_jaad.yaml 
================================================================================
🎯 训练和测试管道启动
================================================================================
配置文件: config_files/my/my_jaad.yaml
开始时间: 2025-11-12 02:25:33

🚀 开始训练...
2025-11-12 02:25:36.551872: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there
 must be at least one NUMA node, so returning NUMA node zero                                                                                                   2025-11-12 02:25:36.555225: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there
 must be at least one NUMA node, so returning NUMA node zero                                                                                                   2025-11-12 02:25:36.555309: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there
 must be at least one NUMA node, so returning NUMA node zero                                                                                                   config_files/my/my_jaad.yaml
model_opts {'model': 'Transformer_depth', 'obs_input_type': ['box', 'depth', 'vehicle_speed', 'ped_speed'], 'enlarge_ratio': 1.5, 'obs_length': 16, 'time_to_ev
ent': [30, 60], 'overlap': 0.8, 'balance_data': False, 'apply_class_weights': True, 'dataset': 'jaad', 'normalize_boxes': True, 'generator': True, 'fusion_point': 'early', 'fusion_method': 'sum'}                                                                                                                           data_opts {'fstride': 1, 'sample_type': 'beh', 'subset': 'default', 'data_split_type': 'default', 'seq_type': 'crossing', 'min_track_size': 76}
net_opts {'num_hidden_units': 256, 'global_pooling': 'avg', 'regularizer_val': 0.0001, 'cell_type': 'gru', 'backbone': 'vgg16', 'dropout': 0.1}
train_opts {'batch_size': 2, 'epochs': 30, 'lr': 5e-05, 'learning_scheduler': {}}
---------------------------------------------------------
Generating action sequence data
fstride: 1
sample_type: beh
subset: default
height_rng: [0, inf]
squarify_ratio: 0
data_split_type: default
seq_type: crossing
min_track_size: 76
random_params: {'ratios': None, 'val_data': True, 'regen_data': False}
kfold_params: {'num_folds': 5, 'fold': 1}
---------------------------------------------------------
Generating database for jaad
jaad database loaded from /home/minshi/Pedestrian_Crossing_Intention_Prediction/JAAD/data_cache/jaad_database.pkl
---------------------------------------------------------
Generating crossing data
Split: train
Number of pedestrians: 324 
Total number of samples: 194 
---------------------------------------------------------
Generating action sequence data
fstride: 1
sample_type: beh
subset: default
height_rng: [0, inf]
squarify_ratio: 0
data_split_type: default
seq_type: crossing
min_track_size: 76
random_params: {'ratios': None, 'val_data': True, 'regen_data': False}
kfold_params: {'num_folds': 5, 'fold': 1}
---------------------------------------------------------
Generating database for jaad
jaad database loaded from /home/minshi/Pedestrian_Crossing_Intention_Prediction/JAAD/data_cache/jaad_database.pkl
---------------------------------------------------------
Generating crossing data
Split: val
Number of pedestrians: 48 
Total number of samples: 22 
---------------------------------------------------------
Generating action sequence data
fstride: 1
sample_type: beh
subset: default
height_rng: [0, inf]
squarify_ratio: 0
data_split_type: default
seq_type: crossing
min_track_size: 76
random_params: {'ratios': None, 'val_data': True, 'regen_data': False}
kfold_params: {'num_folds': 5, 'fold': 1}
---------------------------------------------------------
Generating database for jaad
jaad database loaded from /home/minshi/Pedestrian_Crossing_Intention_Prediction/JAAD/data_cache/jaad_database.pkl
---------------------------------------------------------
Generating crossing data
Split: test
Number of pedestrians: 276 
Total number of samples: 171 
[DataGenerator] auto class_weight -> {0: 0.8247422680412371, 1: 0.17525773195876287}
[DataGenerator] auto class_weight -> {0: 0.7272727272727273, 1: 0.2727272727272727}
2025-11-12 02:25:38.448714: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (o
neDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA                                                                     To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12 02:25:38.450144: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there
 must be at least one NUMA node, so returning NUMA node zero                                                                                                   2025-11-12 02:25:38.450259: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there
 must be at least one NUMA node, so returning NUMA node zero                                                                                                   2025-11-12 02:25:38.450319: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there
 must be at least one NUMA node, so returning NUMA node zero                                                                                                   2025-11-12 02:25:38.715579: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there
 must be at least one NUMA node, so returning NUMA node zero                                                                                                   2025-11-12 02:25:38.715701: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there
 must be at least one NUMA node, so returning NUMA node zero                                                                                                   2025-11-12 02:25:38.715767: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there
 must be at least one NUMA node, so returning NUMA node zero                                                                                                   2025-11-12 02:25:38.715830: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3939 MB m
emory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9                                              
============================================================
📊 MODEL PARAMETER STATISTICS
============================================================
Total parameters:        2,968,717
Trainable parameters:    2,968,711.0
Non-trainable parameters: 6.0
============================================================

/home/minshi/miniconda3/envs/tf26/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learni
ng_rate` instead.                                                                                                                                                warnings.warn(

🚀 Training started!
📁 Models will be saved to: data/models/jaad/Transformer_depth/12Nov2025-02h25m38s
📋 已复制 action_predict.py 到模型目录
2025-11-12 02:25:39.849884: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/30
2025-11-12 02:25:43.695661: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be l
ogged once.                                                                                                                                                    2025-11-12 02:25:43.990112: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8100
1067/1067 [==============================] - 15s 10ms/step - loss: 9.7983 - cls_loss: 0.2092 - reg_loss: 0.0160 - intention_accuracy: 0.5426 - val_loss: 6.1668
 - val_cls_loss: 0.2706 - val_reg_loss: 0.0018 - val_intention_accuracy: 0.5083                                                                                /home/minshi/miniconda3/envs/tf26/lib/python3.8/site-packages/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must
 override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.                                                         warnings.warn('Custom mask layers require a config and must override '
[Sigma] Epoch 1: sigma_cls=0.6883 sigma_reg=0.6663
Epoch 2/30
1067/1067 [==============================] - 10s 9ms/step - loss: 4.2647 - cls_loss: 0.1779 - reg_loss: 0.0068 - intention_accuracy: 0.6317 - val_loss: 3.3024 
- val_cls_loss: 0.2847 - val_reg_loss: 0.0039 - val_intention_accuracy: 0.5826                                                                                 [Sigma] Epoch 2: sigma_cls=0.6795 sigma_reg=0.6404
Epoch 3/30
1067/1067 [==============================] - 10s 9ms/step - loss: 2.4071 - cls_loss: 0.1677 - reg_loss: 0.0049 - intention_accuracy: 0.6453 - val_loss: 2.2037 
- val_cls_loss: 0.3065 - val_reg_loss: 0.0027 - val_intention_accuracy: 0.6033                                                                                 [Sigma] Epoch 3: sigma_cls=0.6701 sigma_reg=0.6152
Epoch 4/30
1067/1067 [==============================] - 10s 9ms/step - loss: 1.5151 - cls_loss: 0.1574 - reg_loss: 0.0041 - intention_accuracy: 0.6720 - val_loss: 1.4349 
- val_cls_loss: 0.2610 - val_reg_loss: 0.0025 - val_intention_accuracy: 0.5992                                                                                 [Sigma] Epoch 4: sigma_cls=0.6606 sigma_reg=0.5908
Epoch 5/30
1067/1067 [==============================] - 10s 9ms/step - loss: 0.9295 - cls_loss: 0.1502 - reg_loss: 0.0031 - intention_accuracy: 0.6912 - val_loss: 1.0167 
- val_cls_loss: 0.2844 - val_reg_loss: 0.0028 - val_intention_accuracy: 0.5744                                                                                 [Sigma] Epoch 5: sigma_cls=0.6510 sigma_reg=0.5671
Epoch 6/30
1067/1067 [==============================] - 10s 9ms/step - loss: 0.5039 - cls_loss: 0.1466 - reg_loss: 0.0028 - intention_accuracy: 0.7048 - val_loss: 0.9002 
- val_cls_loss: 0.3809 - val_reg_loss: 0.0028 - val_intention_accuracy: 0.5496                                                                                 [Sigma] Epoch 6: sigma_cls=0.6418 sigma_reg=0.5441
Epoch 7/30
1067/1067 [==============================] - 17s 16ms/step - loss: 0.1737 - cls_loss: 0.1414 - reg_loss: 0.0024 - intention_accuracy: 0.7001 - val_loss: 0.5034
 - val_cls_loss: 0.3268 - val_reg_loss: 0.0023 - val_intention_accuracy: 0.6240                                                                                [Sigma] Epoch 7: sigma_cls=0.6328 sigma_reg=0.5218
Epoch 8/30
1067/1067 [==============================] - 24s 22ms/step - loss: -0.0799 - cls_loss: 0.1377 - reg_loss: 0.0022 - intention_accuracy: 0.7310 - val_loss: 0.501
2 - val_cls_loss: 0.4045 - val_reg_loss: 0.0015 - val_intention_accuracy: 0.5868                                                                               [Sigma] Epoch 8: sigma_cls=0.6240 sigma_reg=0.5003
Epoch 9/30
1067/1067 [==============================] - 24s 23ms/step - loss: -0.2994 - cls_loss: 0.1265 - reg_loss: 0.0020 - intention_accuracy: 0.7484 - val_loss: 0.368
9 - val_cls_loss: 0.4097 - val_reg_loss: 0.0022 - val_intention_accuracy: 0.5744                                                                               [Sigma] Epoch 9: sigma_cls=0.6148 sigma_reg=0.4794
Epoch 10/30
1067/1067 [==============================] - 24s 22ms/step - loss: -0.4782 - cls_loss: 0.1163 - reg_loss: 0.0020 - intention_accuracy: 0.7774 - val_loss: 0.424
2 - val_cls_loss: 0.4715 - val_reg_loss: 0.0010 - val_intention_accuracy: 0.6529                                                                               [Sigma] Epoch 10: sigma_cls=0.6047 sigma_reg=0.4593
Epoch 11/30
1067/1067 [==============================] - 24s 22ms/step - loss: -0.6209 - cls_loss: 0.1096 - reg_loss: 0.0019 - intention_accuracy: 0.7971 - val_loss: 0.090
5 - val_cls_loss: 0.3805 - val_reg_loss: 0.0019 - val_intention_accuracy: 0.5950                                                                               [Sigma] Epoch 11: sigma_cls=0.5939 sigma_reg=0.4398
Epoch 12/30
1067/1067 [==============================] - 24s 22ms/step - loss: -0.7551 - cls_loss: 0.1008 - reg_loss: 0.0018 - intention_accuracy: 0.8233 - val_loss: 0.180
1 - val_cls_loss: 0.4350 - val_reg_loss: 0.0016 - val_intention_accuracy: 0.6240                                                                               [Sigma] Epoch 12: sigma_cls=0.5826 sigma_reg=0.4210
Epoch 13/30
1067/1067 [==============================] - 24s 22ms/step - loss: -0.8515 - cls_loss: 0.0996 - reg_loss: 0.0017 - intention_accuracy: 0.8135 - val_loss: -0.03
67 - val_cls_loss: 0.3814 - val_reg_loss: 0.0015 - val_intention_accuracy: 0.7025                                                                              [Sigma] Epoch 13: sigma_cls=0.5728 sigma_reg=0.4029
Epoch 14/30
1067/1067 [==============================] - 23s 22ms/step - loss: -0.9763 - cls_loss: 0.0871 - reg_loss: 0.0015 - intention_accuracy: 0.8519 - val_loss: 0.393
3 - val_cls_loss: 0.5328 - val_reg_loss: 0.0015 - val_intention_accuracy: 0.6694                                                                               [Sigma] Epoch 14: sigma_cls=0.5621 sigma_reg=0.3854
Epoch 15/30
1067/1067 [==============================] - 13s 12ms/step - loss: -1.0401 - cls_loss: 0.0915 - reg_loss: 0.0015 - intention_accuracy: 0.8290 - val_loss: 0.395
5 - val_cls_loss: 0.5393 - val_reg_loss: 0.0030 - val_intention_accuracy: 0.6901                                                                               [Sigma] Epoch 15: sigma_cls=0.5525 sigma_reg=0.3685
Epoch 16/30
1067/1067 [==============================] - 12s 11ms/step - loss: -1.1217 - cls_loss: 0.0891 - reg_loss: 0.0015 - intention_accuracy: 0.8280 - val_loss: 0.252
3 - val_cls_loss: 0.5030 - val_reg_loss: 0.0020 - val_intention_accuracy: 0.5165                                                                               [Sigma] Epoch 16: sigma_cls=0.5427 sigma_reg=0.3522
Epoch 17/30
1067/1067 [==============================] - 13s 12ms/step - loss: -1.2197 - cls_loss: 0.0810 - reg_loss: 0.0013 - intention_accuracy: 0.8477 - val_loss: 0.179
5 - val_cls_loss: 0.4873 - val_reg_loss: 0.0014 - val_intention_accuracy: 0.6694                                                                               [Sigma] Epoch 17: sigma_cls=0.5322 sigma_reg=0.3366
Epoch 18/30
1067/1067 [==============================] - 14s 13ms/step - loss: -1.3117 - cls_loss: 0.0748 - reg_loss: 0.0013 - intention_accuracy: 0.8608 - val_loss: 0.336
0 - val_cls_loss: 0.5324 - val_reg_loss: 0.0012 - val_intention_accuracy: 0.6488                                                                               [Sigma] Epoch 18: sigma_cls=0.5216 sigma_reg=0.3216
Epoch 19/30
1067/1067 [==============================] - 22s 20ms/step - loss: -1.3695 - cls_loss: 0.0771 - reg_loss: 0.0013 - intention_accuracy: 0.8590 - val_loss: 0.562
7 - val_cls_loss: 0.5927 - val_reg_loss: 0.0014 - val_intention_accuracy: 0.6405                                                                               [Sigma] Epoch 19: sigma_cls=0.5125 sigma_reg=0.3071
Epoch 20/30
1067/1067 [==============================] - 24s 22ms/step - loss: -1.4347 - cls_loss: 0.0764 - reg_loss: 0.0012 - intention_accuracy: 0.8604 - val_loss: 0.336
1 - val_cls_loss: 0.5360 - val_reg_loss: 8.6089e-04 - val_intention_accuracy: 0.7025                                                                           [Sigma] Epoch 20: sigma_cls=0.5048 sigma_reg=0.2932
Epoch 21/30
1067/1067 [==============================] - 24s 22ms/step - loss: -1.4984 - cls_loss: 0.0753 - reg_loss: 0.0012 - intention_accuracy: 0.8561 - val_loss: 0.530
4 - val_cls_loss: 0.5838 - val_reg_loss: 0.0010 - val_intention_accuracy: 0.6488                                                                               [Sigma] Epoch 21: sigma_cls=0.4969 sigma_reg=0.2798
Epoch 22/30
1067/1067 [==============================] - 24s 22ms/step - loss: -1.5772 - cls_loss: 0.0709 - reg_loss: 0.0011 - intention_accuracy: 0.8754 - val_loss: 0.703
4 - val_cls_loss: 0.6233 - val_reg_loss: 7.6924e-04 - val_intention_accuracy: 0.6570                                                                           [Sigma] Epoch 22: sigma_cls=0.4887 sigma_reg=0.2670
Epoch 23/30
1067/1067 [==============================] - 23s 22ms/step - loss: -1.6502 - cls_loss: 0.0674 - reg_loss: 0.0012 - intention_accuracy: 0.8819 - val_loss: 0.629
0 - val_cls_loss: 0.6037 - val_reg_loss: 8.7675e-04 - val_intention_accuracy: 0.6818                                                                           [Sigma] Epoch 23: sigma_cls=0.4817 sigma_reg=0.2547
Epoch 24/30
1067/1067 [==============================] - 19s 17ms/step - loss: -1.7079 - cls_loss: 0.0679 - reg_loss: 0.0011 - intention_accuracy: 0.8805 - val_loss: 0.773
3 - val_cls_loss: 0.6343 - val_reg_loss: 0.0011 - val_intention_accuracy: 0.6364                                                                               [Sigma] Epoch 24: sigma_cls=0.4750 sigma_reg=0.2429
Epoch 25/30
1067/1067 [==============================] - 12s 12ms/step - loss: -1.7817 - cls_loss: 0.0642 - reg_loss: 0.0011 - intention_accuracy: 0.8871 - val_loss: 1.263
9 - val_cls_loss: 0.7377 - val_reg_loss: 8.3369e-04 - val_intention_accuracy: 0.6529                                                                           [Sigma] Epoch 25: sigma_cls=0.4678 sigma_reg=0.2316
Epoch 26/30
1067/1067 [==============================] - 12s 11ms/step - loss: -1.8560 - cls_loss: 0.0606 - reg_loss: 0.0012 - intention_accuracy: 0.8936 - val_loss: 1.331
4 - val_cls_loss: 0.7421 - val_reg_loss: 0.0011 - val_intention_accuracy: 0.6198                                                                               [Sigma] Epoch 26: sigma_cls=0.4603 sigma_reg=0.2208
Epoch 27/30
1067/1067 [==============================] - 12s 11ms/step - loss: -1.8909 - cls_loss: 0.0651 - reg_loss: 0.0011 - intention_accuracy: 0.8847 - val_loss: 1.297
4 - val_cls_loss: 0.7278 - val_reg_loss: 9.2909e-04 - val_intention_accuracy: 0.6612                                                                           [Sigma] Epoch 27: sigma_cls=0.4538 sigma_reg=0.2104
Epoch 28/30
1067/1067 [==============================] - 13s 12ms/step - loss: -1.9746 - cls_loss: 0.0595 - reg_loss: 0.0011 - intention_accuracy: 0.8969 - val_loss: 0.809
6 - val_cls_loss: 0.6208 - val_reg_loss: 8.1003e-04 - val_intention_accuracy: 0.6653                                                                           [Sigma] Epoch 28: sigma_cls=0.4465 sigma_reg=0.2005
Epoch 29/30
1067/1067 [==============================] - 15s 14ms/step - loss: -2.0280 - cls_loss: 0.0600 - reg_loss: 0.0011 - intention_accuracy: 0.8983 - val_loss: 1.553
3 - val_cls_loss: 0.7601 - val_reg_loss: 9.4206e-04 - val_intention_accuracy: 0.6653                                                                           [Sigma] Epoch 29: sigma_cls=0.4403 sigma_reg=0.1910
Epoch 30/30
1067/1067 [==============================] - 23s 22ms/step - loss: -2.1042 - cls_loss: 0.0563 - reg_loss: 0.0011 - intention_accuracy: 0.8974 - val_loss: 1.763
4 - val_cls_loss: 0.7897 - val_reg_loss: 0.0011 - val_intention_accuracy: 0.6736                                                                               [Sigma] Epoch 30: sigma_cls=0.4339 sigma_reg=0.1819

🎯 Training completed!
📁 All epoch models saved in: data/models/jaad/Transformer_depth/12Nov2025-02h25m38s/epochs
Train model is saved to data/models/jaad/Transformer_depth/12Nov2025-02h25m38s/model.h5
Available metrics: ['loss', 'cls_loss', 'reg_loss', 'intention_accuracy', 'val_loss', 'val_cls_loss', 'val_reg_loss', 'val_intention_accuracy', 'sigma_cls', 'v
al_sigma_cls', 'sigma_reg', 'val_sigma_reg']                                                                                                                   Training plots saved to model directory
Wrote configs to data/models/jaad/Transformer_depth/12Nov2025-02h25m38s/configs.yaml
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 19s 9ms/step

======================================================================
🎯 MODEL TEST RESULTS 🎯
======================================================================
Accuracy:   0.6279
AUC:        0.5685
F1-Score:   0.7301
Precision:  0.6683
Recall:     0.8046
======================================================================

Model saved to data/models/jaad/Transformer_depth/12Nov2025-02h25m38s/

✅ 训练完成 (耗时: 9.4 分钟)
🔍 查找最新模型目录...
📁 找到模型目录: data/models/jaad/Transformer_depth/12Nov2025-02h25m38s

🧪 开始测试模型...
2025-11-12 02:35:01.642524: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there
 must be at least one NUMA node, so returning NUMA node zero                                                                                                   2025-11-12 02:35:01.649024: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there
 must be at least one NUMA node, so returning NUMA node zero                                                                                                   2025-11-12 02:35:01.649235: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there
 must be at least one NUMA node, so returning NUMA node zero                                                                                                   🚀 开始测试模型目录: data/models/jaad/Transformer_depth/12Nov2025-02h25m38s
✅ 配置文件加载成功
✅ 数据集初始化成功
🔄 生成测试数据...
---------------------------------------------------------
Generating action sequence data
fstride: 1
sample_type: beh
subset: default
height_rng: [0, inf]
squarify_ratio: 0
data_split_type: default
seq_type: crossing
min_track_size: 76
random_params: {'ratios': None, 'val_data': True, 'regen_data': False}
kfold_params: {'num_folds': 5, 'fold': 1}
---------------------------------------------------------
Generating database for jaad
jaad database loaded from /home/minshi/Pedestrian_Crossing_Intention_Prediction/JAAD/data_cache/jaad_database.pkl
---------------------------------------------------------
Generating crossing data
Split: test
Number of pedestrians: 276 
Total number of samples: 171 
✅ 测试数据生成完成
📁 找到 31 个模型文件

============================================================
进度: 1/31

🔍 测试模型: epoch_001_loss_6.1668_acc_0.5083.h5
2025-11-12 02:35:03.182008: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (o
neDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA                                                                     To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12 02:35:03.184462: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there
 must be at least one NUMA node, so returning NUMA node zero                                                                                                   2025-11-12 02:35:03.184683: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there
 must be at least one NUMA node, so returning NUMA node zero                                                                                                   2025-11-12 02:35:03.184821: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there
 must be at least one NUMA node, so returning NUMA node zero                                                                                                   2025-11-12 02:35:03.707417: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there
 must be at least one NUMA node, so returning NUMA node zero                                                                                                   2025-11-12 02:35:03.707627: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there
 must be at least one NUMA node, so returning NUMA node zero                                                                                                   2025-11-12 02:35:03.707769: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there
 must be at least one NUMA node, so returning NUMA node zero                                                                                                   2025-11-12 02:35:03.707892: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4107 MB m
emory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9                                              [DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
2025-11-12 02:35:05.553787: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)
2025-11-12 02:35:07.451177: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be l
ogged once.                                                                                                                                                    2025-11-12 02:35:08.054404: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8100
1881/1881 [==============================] - 20s 9ms/step
✅ 准确率: 0.5917, AUC: 0.7143, F1: 0.5987

============================================================
进度: 2/31

🔍 测试模型: epoch_002_loss_3.3024_acc_0.5826.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 18s 9ms/step
✅ 准确率: 0.6619, AUC: 0.7201, F1: 0.6904

============================================================
进度: 3/31

🔍 测试模型: epoch_003_loss_2.2037_acc_0.6033.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 18s 9ms/step
✅ 准确率: 0.6810, AUC: 0.7213, F1: 0.7512

============================================================
进度: 4/31

🔍 测试模型: epoch_004_loss_1.4349_acc_0.5992.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 11s 5ms/step
✅ 准确率: 0.6348, AUC: 0.6809, F1: 0.6657

============================================================
进度: 5/31

🔍 测试模型: epoch_005_loss_1.0167_acc_0.5744.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 9s 5ms/step
✅ 准确率: 0.6550, AUC: 0.7106, F1: 0.6805

============================================================
进度: 6/31

🔍 测试模型: epoch_006_loss_0.9002_acc_0.5496.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 9s 5ms/step
✅ 准确率: 0.6821, AUC: 0.7228, F1: 0.7363

============================================================
进度: 7/31

🔍 测试模型: epoch_007_loss_0.5034_acc_0.6240.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 9s 5ms/step
✅ 准确率: 0.6146, AUC: 0.6514, F1: 0.7210

============================================================
进度: 8/31

🔍 测试模型: epoch_008_loss_0.5012_acc_0.5868.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 10s 5ms/step
✅ 准确率: 0.6534, AUC: 0.7143, F1: 0.6981

============================================================
进度: 9/31

🔍 测试模型: epoch_009_loss_0.3689_acc_0.5744.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 11s 5ms/step
✅ 准确率: 0.6497, AUC: 0.6891, F1: 0.7180

============================================================
进度: 10/31

🔍 测试模型: epoch_010_loss_0.4242_acc_0.6529.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 15s 7ms/step
✅ 准确率: 0.6231, AUC: 0.6827, F1: 0.7317

============================================================
进度: 11/31

🔍 测试模型: epoch_011_loss_0.0905_acc_0.5950.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 19s 9ms/step
✅ 准确率: 0.5875, AUC: 0.6143, F1: 0.6644

============================================================
进度: 12/31

🔍 测试模型: epoch_012_loss_0.1801_acc_0.6240.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 19s 10ms/step
✅ 准确率: 0.6284, AUC: 0.6743, F1: 0.6933

============================================================
进度: 13/31

🔍 测试模型: epoch_013_loss_-0.0367_acc_0.7025.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 19s 9ms/step
✅ 准确率: 0.6449, AUC: 0.6689, F1: 0.7155

============================================================
进度: 14/31

🔍 测试模型: epoch_014_loss_0.3933_acc_0.6694.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 18s 9ms/step
✅ 准确率: 0.6417, AUC: 0.6623, F1: 0.7267

============================================================
进度: 15/31

🔍 测试模型: epoch_015_loss_0.3955_acc_0.6901.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 16s 8ms/step
✅ 准确率: 0.6061, AUC: 0.6472, F1: 0.7018

============================================================
进度: 16/31

🔍 测试模型: epoch_016_loss_0.2523_acc_0.5165.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 10s 5ms/step
✅ 准确率: 0.6135, AUC: 0.6362, F1: 0.6782

============================================================
进度: 17/31

🔍 测试模型: epoch_017_loss_0.1795_acc_0.6694.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 9s 4ms/step
✅ 准确率: 0.6252, AUC: 0.6389, F1: 0.6860

============================================================
进度: 18/31

🔍 测试模型: epoch_018_loss_0.3360_acc_0.6488.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 9s 5ms/step
✅ 准确率: 0.6194, AUC: 0.6451, F1: 0.7027

============================================================
进度: 19/31

🔍 测试模型: epoch_019_loss_0.5627_acc_0.6405.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 10s 5ms/step
✅ 准确率: 0.6093, AUC: 0.6469, F1: 0.7033

============================================================
进度: 20/31

🔍 测试模型: epoch_020_loss_0.3361_acc_0.7025.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 10s 5ms/step
✅ 准确率: 0.6353, AUC: 0.6588, F1: 0.7220

============================================================
进度: 21/31

🔍 测试模型: epoch_021_loss_0.5304_acc_0.6488.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 16s 8ms/step
✅ 准确率: 0.6183, AUC: 0.6432, F1: 0.7112

============================================================
进度: 22/31

🔍 测试模型: epoch_022_loss_0.7034_acc_0.6570.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 18s 9ms/step
✅ 准确率: 0.6146, AUC: 0.6368, F1: 0.7056

============================================================
进度: 23/31

🔍 测试模型: epoch_023_loss_0.6290_acc_0.6818.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 18s 9ms/step
✅ 准确率: 0.6034, AUC: 0.6389, F1: 0.7124

============================================================
进度: 24/31

🔍 测试模型: epoch_024_loss_0.7733_acc_0.6364.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 17s 8ms/step
✅ 准确率: 0.6310, AUC: 0.6702, F1: 0.7231

============================================================
进度: 25/31

🔍 测试模型: epoch_025_loss_1.2639_acc_0.6529.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 14s 7ms/step
✅ 准确率: 0.6231, AUC: 0.6567, F1: 0.7240

============================================================
进度: 26/31

🔍 测试模型: epoch_026_loss_1.3314_acc_0.6198.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 10s 5ms/step
✅ 准确率: 0.6108, AUC: 0.6307, F1: 0.7079

============================================================
进度: 27/31

🔍 测试模型: epoch_027_loss_1.2974_acc_0.6612.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 9s 4ms/step
✅ 准确率: 0.6316, AUC: 0.6485, F1: 0.7298

============================================================
进度: 28/31

🔍 测试模型: epoch_028_loss_0.8096_acc_0.6653.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 8s 4ms/step
✅ 准确率: 0.6162, AUC: 0.6522, F1: 0.7114

============================================================
进度: 29/31

🔍 测试模型: epoch_029_loss_1.5533_acc_0.6653.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 7s 4ms/step
✅ 准确率: 0.6135, AUC: 0.6504, F1: 0.7074

============================================================
进度: 30/31

🔍 测试模型: epoch_030_loss_1.7634_acc_0.6736.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 8s 4ms/step
✅ 准确率: 0.6279, AUC: 0.6581, F1: 0.7301

============================================================
进度: 31/31

🔍 测试模型: model.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 9s 4ms/step
✅ 准确率: 0.6279, AUC: 0.6581, F1: 0.7301

📊 结果已保存到: data/models/jaad/Transformer_depth/12Nov2025-02h25m38s/test_results_20251112_024226.csv
📝 报告已保存到: data/models/jaad/Transformer_depth/12Nov2025-02h25m38s/test_report_20251112_024226.txt

🏆 准确率最高的模型: epoch_006_loss_0.9002_acc_0.5496.h5 (准确率: 0.6821)
🗑️  开始清理epochs目录，将删除 30 个模型文件...
🗑️  已删除: epoch_023_loss_0.6290_acc_0.6818.h5
🗑️  已删除: epoch_007_loss_0.5034_acc_0.6240.h5
🗑️  已删除: epoch_008_loss_0.5012_acc_0.5868.h5
🗑️  已删除: epoch_028_loss_0.8096_acc_0.6653.h5
🗑️  已删除: epoch_026_loss_1.3314_acc_0.6198.h5
🗑️  已删除: epoch_018_loss_0.3360_acc_0.6488.h5
🗑️  已删除: epoch_002_loss_3.3024_acc_0.5826.h5
🗑️  已删除: epoch_024_loss_0.7733_acc_0.6364.h5
🗑️  已删除: epoch_009_loss_0.3689_acc_0.5744.h5
🗑️  已删除: epoch_014_loss_0.3933_acc_0.6694.h5
🗑️  已删除: epoch_019_loss_0.5627_acc_0.6405.h5
🗑️  已删除: epoch_020_loss_0.3361_acc_0.7025.h5
🗑️  已删除: epoch_025_loss_1.2639_acc_0.6529.h5
🗑️  已删除: epoch_001_loss_6.1668_acc_0.5083.h5
🗑️  已删除: epoch_003_loss_2.2037_acc_0.6033.h5
🗑️  已删除: epoch_015_loss_0.3955_acc_0.6901.h5
🗑️  已删除: epoch_016_loss_0.2523_acc_0.5165.h5
🗑️  已删除: epoch_011_loss_0.0905_acc_0.5950.h5
🗑️  已删除: epoch_005_loss_1.0167_acc_0.5744.h5
📋 已将最佳模型复制到: data/models/jaad/Transformer_depth/12Nov2025-02h25m38s/epoch_006_loss_0.9002_acc_0.5496.h5
🗑️  已删除: epoch_006_loss_0.9002_acc_0.5496.h5
🗑️  已删除: epoch_021_loss_0.5304_acc_0.6488.h5
🗑️  已删除: epoch_027_loss_1.2974_acc_0.6612.h5
🗑️  已删除: epoch_017_loss_0.1795_acc_0.6694.h5
🗑️  已删除: epoch_029_loss_1.5533_acc_0.6653.h5
🗑️  已删除: epoch_012_loss_0.1801_acc_0.6240.h5
🗑️  已删除: epoch_013_loss_-0.0367_acc_0.7025.h5
🗑️  已删除: epoch_030_loss_1.7634_acc_0.6736.h5
🗑️  已删除: epoch_010_loss_0.4242_acc_0.6529.h5
🗑️  已删除: epoch_022_loss_0.7034_acc_0.6570.h5
🗑️  已删除: epoch_004_loss_1.4349_acc_0.5992.h5
🗑️  已删除空的epochs目录
🔄 模型目录已重命名:
   原目录: 12Nov2025-02h25m38s
   新目录: 12Nov2025-02h25m38s_acc_0.6821

================================================================================
🎯 测试结果汇总
================================================================================
总模型数量: 31
成功测试: 31
失败测试: 0

📊 性能统计:
平均准确率: 0.6283 (±0.0225)
平均AUC: 0.6659 (±0.0300)
平均F1: 0.7058 (±0.0285)

🏆 最佳模型:
最高准确率: epoch_006_loss_0.9002_acc_0.5496.h5 (Acc: 0.6821)
最高AUC: epoch_006_loss_0.9002_acc_0.5496.h5 (AUC: 0.7228)
最高F1: epoch_003_loss_2.2037_acc_0.6033.h5 (F1: 0.7512)

✅ 测试完成 (耗时: 7.5 分钟)

================================================================================
🎉 训练和测试管道完成!
================================================================================
模型目录: data/models/jaad/Transformer_depth/12Nov2025-02h25m38s
总耗时: 16.9 分钟
结束时间: 2025-11-12 02:42:28
================================================================================
