 cd /home/minshi/Pedestrian_Crossing_Intention_Prediction ; /usr/bin/env /home/minshi/miniconda3/envs/tf26/bin/python /home/minshi/.vscode/extensions/ms-python.debugpy-2025.14.1-linux-x64/bundled/libs/debugpy/adapter/../../debugpy/launcher 45661 -- /home/minshi/Pedestrian_Crossing_Intention_Prediction/train_and_test_all_epoch_pipeline.py -c config_files/my/my_jaad.yaml 
================================================================================
🎯 训练和测试管道启动
================================================================================
配置文件: config_files/my/my_jaad.yaml
开始时间: 2025-11-12 06:37:13

🚀 开始训练...
2025-11-12 06:37:15.882603: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must
 be at least one NUMA node, so returning NUMA node zero                                                                                                             2025-11-12 06:37:15.886075: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must
 be at least one NUMA node, so returning NUMA node zero                                                                                                             2025-11-12 06:37:15.886181: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must
 be at least one NUMA node, so returning NUMA node zero                                                                                                             config_files/my/my_jaad.yaml
model_opts {'model': 'Transformer_depth', 'obs_input_type': ['box', 'depth', 'vehicle_speed', 'ped_speed'], 'enlarge_ratio': 1.5, 'obs_length': 16, 'time_to_event':
 [30, 60], 'overlap': 0.8, 'balance_data': False, 'apply_class_weights': True, 'dataset': 'jaad', 'normalize_boxes': True, 'generator': True, 'fusion_point': 'early', 'fusion_method': 'sum'}                                                                                                                                          data_opts {'fstride': 1, 'sample_type': 'beh', 'subset': 'default', 'data_split_type': 'default', 'seq_type': 'crossing', 'min_track_size': 76}
net_opts {'num_hidden_units': 256, 'global_pooling': 'avg', 'regularizer_val': 0.0001, 'cell_type': 'gru', 'backbone': 'vgg16', 'dropout': 0.1}
train_opts {'batch_size': 2, 'epochs': 30, 'lr': 5e-05, 'learning_scheduler': {}}
---------------------------------------------------------
Generating action sequence data
fstride: 1
sample_type: beh
subset: default
height_rng: [0, inf]
squarify_ratio: 0
data_split_type: default
seq_type: crossing
min_track_size: 76
random_params: {'ratios': None, 'val_data': True, 'regen_data': False}
kfold_params: {'num_folds': 5, 'fold': 1}
---------------------------------------------------------
Generating database for jaad
jaad database loaded from /home/minshi/Pedestrian_Crossing_Intention_Prediction/JAAD/data_cache/jaad_database.pkl
---------------------------------------------------------
Generating crossing data
Split: train
Number of pedestrians: 324 
Total number of samples: 194 
---------------------------------------------------------
Generating action sequence data
fstride: 1
sample_type: beh
subset: default
height_rng: [0, inf]
squarify_ratio: 0
data_split_type: default
seq_type: crossing
min_track_size: 76
random_params: {'ratios': None, 'val_data': True, 'regen_data': False}
kfold_params: {'num_folds': 5, 'fold': 1}
---------------------------------------------------------
Generating database for jaad
jaad database loaded from /home/minshi/Pedestrian_Crossing_Intention_Prediction/JAAD/data_cache/jaad_database.pkl
---------------------------------------------------------
Generating crossing data
Split: val
Number of pedestrians: 48 
Total number of samples: 22 
---------------------------------------------------------
Generating action sequence data
fstride: 1
sample_type: beh
subset: default
height_rng: [0, inf]
squarify_ratio: 0
data_split_type: default
seq_type: crossing
min_track_size: 76
random_params: {'ratios': None, 'val_data': True, 'regen_data': False}
kfold_params: {'num_folds': 5, 'fold': 1}
---------------------------------------------------------
Generating database for jaad
jaad database loaded from /home/minshi/Pedestrian_Crossing_Intention_Prediction/JAAD/data_cache/jaad_database.pkl
---------------------------------------------------------
Generating crossing data
Split: test
Number of pedestrians: 276 
Total number of samples: 171 
[DataGenerator] auto class_weight -> {0: 0.8247422680412371, 1: 0.17525773195876287}
[DataGenerator] auto class_weight -> {0: 0.7272727272727273, 1: 0.2727272727272727}
2025-11-12 06:37:17.785235: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN
) to use the following CPU instructions in performance-critical operations:  AVX2 FMA                                                                               To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12 06:37:17.786676: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must
 be at least one NUMA node, so returning NUMA node zero                                                                                                             2025-11-12 06:37:17.786851: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must
 be at least one NUMA node, so returning NUMA node zero                                                                                                             2025-11-12 06:37:17.786963: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must
 be at least one NUMA node, so returning NUMA node zero                                                                                                             2025-11-12 06:37:18.096424: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must
 be at least one NUMA node, so returning NUMA node zero                                                                                                             2025-11-12 06:37:18.096522: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must
 be at least one NUMA node, so returning NUMA node zero                                                                                                             2025-11-12 06:37:18.096584: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must
 be at least one NUMA node, so returning NUMA node zero                                                                                                             2025-11-12 06:37:18.096644: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3474 MB memory
:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9                                                        
============================================================
📊 MODEL PARAMETER STATISTICS
============================================================
Total parameters:        2,968,717
Trainable parameters:    2,968,711
Non-trainable parameters: 6
============================================================

/home/minshi/miniconda3/envs/tf26/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_ra
te` instead.                                                                                                                                                          warnings.warn(

🚀 Training started!
📁 Models will be saved to: data/models/jaad/Transformer_depth/12Nov2025-06h37m17s
📋 已复制 action_predict.py 到模型目录
2025-11-12 06:37:19.270085: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/30
2025-11-12 06:37:23.466595: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged
 once.                                                                                                                                                              2025-11-12 06:37:23.774609: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8100
1067/1067 [==============================] - 16s 10ms/step - loss: 12.1379 - cls_loss: 0.2124 - reg_loss: 0.0221 - intention_accuracy: 0.5483 - val_loss: 9.4281 - v
al_cls_loss: 0.2759 - val_reg_loss: 0.0042 - val_intention_accuracy: 0.2769                                                                                         /home/minshi/miniconda3/envs/tf26/lib/python3.8/site-packages/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must over
ride get_config. When loading, the custom mask layer must be passed to the custom_objects argument.                                                                   warnings.warn('Custom mask layers require a config and must override '
[Sigma] Epoch 1: sigma_cls=0.4282 sigma_reg=1.1157
Epoch 2/30
1067/1067 [==============================] - 11s 10ms/step - loss: 7.1833 - cls_loss: 0.1876 - reg_loss: 0.0110 - intention_accuracy: 0.5975 - val_loss: 6.3726 - va
l_cls_loss: 0.2962 - val_reg_loss: 0.0038 - val_intention_accuracy: 0.5868                                                                                          [Sigma] Epoch 2: sigma_cls=0.4501 sigma_reg=1.0606
Epoch 3/30
1067/1067 [==============================] - 10s 10ms/step - loss: 4.8989 - cls_loss: 0.1672 - reg_loss: 0.0074 - intention_accuracy: 0.6593 - val_loss: 4.6296 - va
l_cls_loss: 0.2626 - val_reg_loss: 0.0045 - val_intention_accuracy: 0.6653                                                                                          [Sigma] Epoch 3: sigma_cls=0.4658 sigma_reg=1.0050
Epoch 4/30
1067/1067 [==============================] - 12s 11ms/step - loss: 3.6272 - cls_loss: 0.1583 - reg_loss: 0.0057 - intention_accuracy: 0.6809 - val_loss: 4.1657 - va
l_cls_loss: 0.3869 - val_reg_loss: 0.0047 - val_intention_accuracy: 0.5909                                                                                          [Sigma] Epoch 4: sigma_cls=0.4781 sigma_reg=0.9491
Epoch 5/30
1067/1067 [==============================] - 19s 18ms/step - loss: 2.7836 - cls_loss: 0.1548 - reg_loss: 0.0045 - intention_accuracy: 0.6832 - val_loss: 2.9923 - va
l_cls_loss: 0.2837 - val_reg_loss: 0.0057 - val_intention_accuracy: 0.5331                                                                                          [Sigma] Epoch 5: sigma_cls=0.4885 sigma_reg=0.8930
Epoch 6/30
1067/1067 [==============================] - 24s 22ms/step - loss: 2.1135 - cls_loss: 0.1417 - reg_loss: 0.0038 - intention_accuracy: 0.6949 - val_loss: 2.9230 - va
l_cls_loss: 0.4043 - val_reg_loss: 0.0037 - val_intention_accuracy: 0.6653                                                                                          [Sigma] Epoch 6: sigma_cls=0.4949 sigma_reg=0.8367
Epoch 7/30
1067/1067 [==============================] - 24s 22ms/step - loss: 1.5914 - cls_loss: 0.1346 - reg_loss: 0.0033 - intention_accuracy: 0.7221 - val_loss: 2.6105 - va
l_cls_loss: 0.4419 - val_reg_loss: 0.0031 - val_intention_accuracy: 0.5992                                                                                          [Sigma] Epoch 7: sigma_cls=0.4981 sigma_reg=0.7801
Epoch 8/30
1067/1067 [==============================] - 24s 23ms/step - loss: 1.1475 - cls_loss: 0.1277 - reg_loss: 0.0026 - intention_accuracy: 0.7151 - val_loss: 2.2916 - va
l_cls_loss: 0.4583 - val_reg_loss: 0.0042 - val_intention_accuracy: 0.5496                                                                                          [Sigma] Epoch 8: sigma_cls=0.4992 sigma_reg=0.7234
Epoch 9/30
1067/1067 [==============================] - 24s 22ms/step - loss: 0.7598 - cls_loss: 0.1190 - reg_loss: 0.0023 - intention_accuracy: 0.7587 - val_loss: 1.8818 - va
l_cls_loss: 0.4359 - val_reg_loss: 0.0028 - val_intention_accuracy: 0.6240                                                                                          [Sigma] Epoch 9: sigma_cls=0.4973 sigma_reg=0.6663
Epoch 10/30
1067/1067 [==============================] - 23s 21ms/step - loss: 0.4199 - cls_loss: 0.1109 - reg_loss: 0.0021 - intention_accuracy: 0.7826 - val_loss: 2.1210 - va
l_cls_loss: 0.5587 - val_reg_loss: 0.0023 - val_intention_accuracy: 0.6116                                                                                          [Sigma] Epoch 10: sigma_cls=0.4930 sigma_reg=0.6090
Epoch 11/30
1067/1067 [==============================] - 24s 22ms/step - loss: 0.1075 - cls_loss: 0.1017 - reg_loss: 0.0019 - intention_accuracy: 0.8149 - val_loss: 1.9681 - va
l_cls_loss: 0.5708 - val_reg_loss: 0.0018 - val_intention_accuracy: 0.5248                                                                                          [Sigma] Epoch 11: sigma_cls=0.4857 sigma_reg=0.5514
Epoch 12/30
1067/1067 [==============================] - 24s 23ms/step - loss: -0.1732 - cls_loss: 0.0933 - reg_loss: 0.0019 - intention_accuracy: 0.8252 - val_loss: 2.4003 - v
al_cls_loss: 0.7043 - val_reg_loss: 0.0021 - val_intention_accuracy: 0.7025                                                                                         [Sigma] Epoch 12: sigma_cls=0.4767 sigma_reg=0.4933
Epoch 13/30
1067/1067 [==============================] - 23s 22ms/step - loss: -0.4342 - cls_loss: 0.0867 - reg_loss: 0.0017 - intention_accuracy: 0.8374 - val_loss: 2.0122 - v
al_cls_loss: 0.6416 - val_reg_loss: 0.0023 - val_intention_accuracy: 0.6570                                                                                         [Sigma] Epoch 13: sigma_cls=0.4658 sigma_reg=0.4346
Epoch 14/30
1067/1067 [==============================] - 23s 21ms/step - loss: -0.6515 - cls_loss: 0.0887 - reg_loss: 0.0016 - intention_accuracy: 0.8336 - val_loss: 1.8917 - v
al_cls_loss: 0.6459 - val_reg_loss: 0.0016 - val_intention_accuracy: 0.6405                                                                                         [Sigma] Epoch 14: sigma_cls=0.4581 sigma_reg=0.3753
Epoch 15/30
1067/1067 [==============================] - 23s 22ms/step - loss: -0.9129 - cls_loss: 0.0818 - reg_loss: 0.0015 - intention_accuracy: 0.8524 - val_loss: 1.5134 - v
al_cls_loss: 0.5958 - val_reg_loss: 0.0019 - val_intention_accuracy: 0.5744                                                                                         [Sigma] Epoch 15: sigma_cls=0.4497 sigma_reg=0.3151
Epoch 16/30
1067/1067 [==============================] - 23s 22ms/step - loss: -1.1557 - cls_loss: 0.0833 - reg_loss: 0.0014 - intention_accuracy: 0.8435 - val_loss: 0.7175 - v
al_cls_loss: 0.4758 - val_reg_loss: 0.0016 - val_intention_accuracy: 0.5289                                                                                         [Sigma] Epoch 16: sigma_cls=0.4426 sigma_reg=0.2535
Epoch 17/30
1067/1067 [==============================] - 23s 22ms/step - loss: -1.4439 - cls_loss: 0.0825 - reg_loss: 0.0013 - intention_accuracy: 0.8369 - val_loss: 2.2195 - v
al_cls_loss: 0.8151 - val_reg_loss: 8.2901e-04 - val_intention_accuracy: 0.6281                                                                                     [Sigma] Epoch 17: sigma_cls=0.4368 sigma_reg=0.1903
Epoch 18/30
1067/1067 [==============================] - 23s 22ms/step - loss: -1.8455 - cls_loss: 0.0754 - reg_loss: 0.0012 - intention_accuracy: 0.8557 - val_loss: 0.8726 - v
al_cls_loss: 0.6097 - val_reg_loss: 0.0016 - val_intention_accuracy: 0.6281                                                                                         [Sigma] Epoch 18: sigma_cls=0.4282 sigma_reg=0.1253
Epoch 19/30
1067/1067 [==============================] - 15s 14ms/step - loss: -2.3470 - cls_loss: 0.0691 - reg_loss: 0.0012 - intention_accuracy: 0.8707 - val_loss: 0.3739 - v
al_cls_loss: 0.5893 - val_reg_loss: 0.0011 - val_intention_accuracy: 0.6322                                                                                         [Sigma] Epoch 19: sigma_cls=0.4184 sigma_reg=0.0670
Epoch 20/30
1067/1067 [==============================] - 13s 12ms/step - loss: -2.6827 - cls_loss: 0.0701 - reg_loss: 0.0011 - intention_accuracy: 0.8618 - val_loss: -0.0406 - 
val_cls_loss: 0.5454 - val_reg_loss: 7.5566e-04 - val_intention_accuracy: 0.5661                                                                                    [Sigma] Epoch 20: sigma_cls=0.4108 sigma_reg=0.0484
Epoch 21/30
1067/1067 [==============================] - 14s 13ms/step - loss: -2.8440 - cls_loss: 0.0686 - reg_loss: 8.6544e-04 - intention_accuracy: 0.8707 - val_loss: 0.1893
 - val_cls_loss: 0.5909 - val_reg_loss: 5.7829e-04 - val_intention_accuracy: 0.6033                                                                                 [Sigma] Epoch 21: sigma_cls=0.4036 sigma_reg=0.0428
Epoch 22/30
1067/1067 [==============================] - 20s 19ms/step - loss: -2.9623 - cls_loss: 0.0647 - reg_loss: 7.5235e-04 - intention_accuracy: 0.8838 - val_loss: 0.6369
 - val_cls_loss: 0.6388 - val_reg_loss: 6.7763e-04 - val_intention_accuracy: 0.6364                                                                                 [Sigma] Epoch 22: sigma_cls=0.3961 sigma_reg=0.0389
Epoch 23/30
1067/1067 [==============================] - 23s 22ms/step - loss: -3.0227 - cls_loss: 0.0612 - reg_loss: 7.2352e-04 - intention_accuracy: 0.8847 - val_loss: 2.6421
 - val_cls_loss: 0.9323 - val_reg_loss: 5.6302e-04 - val_intention_accuracy: 0.6777                                                                                 [Sigma] Epoch 23: sigma_cls=0.3880 sigma_reg=0.0378
Epoch 24/30
1067/1067 [==============================] - 23s 22ms/step - loss: -3.1103 - cls_loss: 0.0598 - reg_loss: 6.3813e-04 - intention_accuracy: 0.8927 - val_loss: -0.214
7 - val_cls_loss: 0.4449 - val_reg_loss: 9.3012e-04 - val_intention_accuracy: 0.6281                                                                                [Sigma] Epoch 24: sigma_cls=0.3797 sigma_reg=0.0355
Epoch 25/30
1067/1067 [==============================] - 23s 22ms/step - loss: -3.1606 - cls_loss: 0.0567 - reg_loss: 6.1944e-04 - intention_accuracy: 0.8993 - val_loss: -0.022
3 - val_cls_loss: 0.4941 - val_reg_loss: 6.0595e-04 - val_intention_accuracy: 0.6612                                                                                [Sigma] Epoch 25: sigma_cls=0.3723 sigma_reg=0.0356
Epoch 26/30
1067/1067 [==============================] - 23s 22ms/step - loss: -3.1908 - cls_loss: 0.0572 - reg_loss: 5.9223e-04 - intention_accuracy: 0.8988 - val_loss: 0.5487
 - val_cls_loss: 0.5510 - val_reg_loss: 6.6462e-04 - val_intention_accuracy: 0.5950                                                                                 [Sigma] Epoch 26: sigma_cls=0.3660 sigma_reg=0.0346
Epoch 27/30
1067/1067 [==============================] - 24s 23ms/step - loss: -3.2350 - cls_loss: 0.0580 - reg_loss: 5.4682e-04 - intention_accuracy: 0.9021 - val_loss: 1.9621
 - val_cls_loss: 0.7329 - val_reg_loss: 5.8834e-04 - val_intention_accuracy: 0.6653                                                                                 [Sigma] Epoch 27: sigma_cls=0.3615 sigma_reg=0.0330
Epoch 28/30
1067/1067 [==============================] - 24s 22ms/step - loss: -3.2841 - cls_loss: 0.0545 - reg_loss: 5.3188e-04 - intention_accuracy: 0.9138 - val_loss: 1.9201
 - val_cls_loss: 0.7154 - val_reg_loss: 5.3877e-04 - val_intention_accuracy: 0.6240                                                                                 [Sigma] Epoch 28: sigma_cls=0.3564 sigma_reg=0.0324
Epoch 29/30
1067/1067 [==============================] - 24s 22ms/step - loss: -3.3014 - cls_loss: 0.0540 - reg_loss: 5.2524e-04 - intention_accuracy: 0.8983 - val_loss: 3.1360
 - val_cls_loss: 0.8473 - val_reg_loss: 5.6426e-04 - val_intention_accuracy: 0.6570                                                                                 [Sigma] Epoch 29: sigma_cls=0.3519 sigma_reg=0.0326
Epoch 30/30
1067/1067 [==============================] - 23s 21ms/step - loss: -3.3290 - cls_loss: 0.0554 - reg_loss: 4.9207e-04 - intention_accuracy: 0.9086 - val_loss: 2.1209
 - val_cls_loss: 0.7055 - val_reg_loss: 6.0922e-04 - val_intention_accuracy: 0.6281                                                                                 [Sigma] Epoch 30: sigma_cls=0.3490 sigma_reg=0.0316

🎯 Training completed!
📁 All epoch models saved in: data/models/jaad/Transformer_depth/12Nov2025-06h37m17s/epochs
Train model is saved to data/models/jaad/Transformer_depth/12Nov2025-06h37m17s/model.h5
Available metrics: ['loss', 'cls_loss', 'reg_loss', 'intention_accuracy', 'val_loss', 'val_cls_loss', 'val_reg_loss', 'val_intention_accuracy', 'sigma_cls', 'val_si
gma_cls', 'sigma_reg', 'val_sigma_reg']                                                                                                                             Training plots saved to model directory
Wrote configs to data/models/jaad/Transformer_depth/12Nov2025-06h37m17s/configs.yaml
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 19s 10ms/step

======================================================================
🎯 MODEL TEST RESULTS 🎯
======================================================================
Accuracy:   0.6199
AUC:        0.5644
F1-Score:   0.7210
Precision:  0.6667
Recall:     0.7850
======================================================================

Model saved to data/models/jaad/Transformer_depth/12Nov2025-06h37m17s/

✅ 训练完成 (耗时: 11.1 分钟)
🔍 查找最新模型目录...
📁 找到模型目录: data/models/jaad/Transformer_depth/12Nov2025-06h37m17s

🧪 开始测试模型...
2025-11-12 06:48:23.328623: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must
 be at least one NUMA node, so returning NUMA node zero                                                                                                             2025-11-12 06:48:23.335184: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must
 be at least one NUMA node, so returning NUMA node zero                                                                                                             2025-11-12 06:48:23.335391: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must
 be at least one NUMA node, so returning NUMA node zero                                                                                                             🚀 开始测试模型目录: data/models/jaad/Transformer_depth/12Nov2025-06h37m17s
✅ 配置文件加载成功
✅ 数据集初始化成功
🔄 生成测试数据...
---------------------------------------------------------
Generating action sequence data
fstride: 1
sample_type: beh
subset: default
height_rng: [0, inf]
squarify_ratio: 0
data_split_type: default
seq_type: crossing
min_track_size: 76
random_params: {'ratios': None, 'val_data': True, 'regen_data': False}
kfold_params: {'num_folds': 5, 'fold': 1}
---------------------------------------------------------
Generating database for jaad
jaad database loaded from /home/minshi/Pedestrian_Crossing_Intention_Prediction/JAAD/data_cache/jaad_database.pkl
---------------------------------------------------------
Generating crossing data
Split: test
Number of pedestrians: 276 
Total number of samples: 171 
✅ 测试数据生成完成
📁 找到 31 个模型文件

============================================================
进度: 1/31

🔍 测试模型: epoch_001_loss_9.4281_acc_0.2769.h5
2025-11-12 06:48:24.839083: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN
) to use the following CPU instructions in performance-critical operations:  AVX2 FMA                                                                               To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12 06:48:24.841477: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must
 be at least one NUMA node, so returning NUMA node zero                                                                                                             2025-11-12 06:48:24.841713: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must
 be at least one NUMA node, so returning NUMA node zero                                                                                                             2025-11-12 06:48:24.841848: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must
 be at least one NUMA node, so returning NUMA node zero                                                                                                             2025-11-12 06:48:25.385746: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must
 be at least one NUMA node, so returning NUMA node zero                                                                                                             2025-11-12 06:48:25.385958: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must
 be at least one NUMA node, so returning NUMA node zero                                                                                                             2025-11-12 06:48:25.386116: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must
 be at least one NUMA node, so returning NUMA node zero                                                                                                             2025-11-12 06:48:25.386240: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3645 MB memory
:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9                                                        [DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
2025-11-12 06:48:27.230203: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)
2025-11-12 06:48:29.179310: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged
 once.                                                                                                                                                              2025-11-12 06:48:29.804383: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8100
1881/1881 [==============================] - 22s 10ms/step
✅ 准确率: 0.3860, AUC: 0.6675, F1: 0.0415

============================================================
进度: 2/31

🔍 测试模型: epoch_002_loss_6.3726_acc_0.5868.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 20s 10ms/step
✅ 准确率: 0.6699, AUC: 0.7317, F1: 0.7317

============================================================
进度: 3/31

🔍 测试模型: epoch_003_loss_4.6296_acc_0.6653.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 21s 10ms/step
✅ 准确率: 0.6576, AUC: 0.6962, F1: 0.7183

============================================================
进度: 4/31

🔍 测试模型: epoch_004_loss_4.1657_acc_0.5909.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 18s 9ms/step
✅ 准确率: 0.6863, AUC: 0.7159, F1: 0.7517

============================================================
进度: 5/31

🔍 测试模型: epoch_005_loss_2.9923_acc_0.5331.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 12s 6ms/step
✅ 准确率: 0.5922, AUC: 0.7006, F1: 0.5727

============================================================
进度: 6/31

🔍 测试模型: epoch_006_loss_2.9230_acc_0.6653.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 12s 6ms/step
✅ 准确率: 0.6156, AUC: 0.6765, F1: 0.7433

============================================================
进度: 7/31

🔍 测试模型: epoch_007_loss_2.6105_acc_0.5992.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 11s 5ms/step
✅ 准确率: 0.6560, AUC: 0.7019, F1: 0.7003

============================================================
进度: 8/31

🔍 测试模型: epoch_008_loss_2.2916_acc_0.5496.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 13s 6ms/step
✅ 准确率: 0.6528, AUC: 0.6929, F1: 0.6924

============================================================
进度: 9/31

🔍 测试模型: epoch_009_loss_1.8818_acc_0.6240.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 18s 9ms/step
✅ 准确率: 0.6427, AUC: 0.6769, F1: 0.6970

============================================================
进度: 10/31

🔍 测试模型: epoch_010_loss_2.1210_acc_0.6116.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 19s 10ms/step
✅ 准确率: 0.6310, AUC: 0.6902, F1: 0.7104

============================================================
进度: 11/31

🔍 测试模型: epoch_011_loss_1.9681_acc_0.5248.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 18s 9ms/step
✅ 准确率: 0.6326, AUC: 0.6826, F1: 0.6968

============================================================
进度: 12/31

🔍 测试模型: epoch_012_loss_2.4003_acc_0.7025.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 19s 9ms/step
✅ 准确率: 0.5747, AUC: 0.6283, F1: 0.6944

============================================================
进度: 13/31

🔍 测试模型: epoch_013_loss_2.0122_acc_0.6570.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 19s 9ms/step
✅ 准确率: 0.6534, AUC: 0.6846, F1: 0.7230

============================================================
进度: 14/31

🔍 测试模型: epoch_014_loss_1.8917_acc_0.6405.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 10s 5ms/step
✅ 准确率: 0.6289, AUC: 0.6597, F1: 0.7104

============================================================
进度: 15/31

🔍 测试模型: epoch_015_loss_1.5134_acc_0.5744.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 11s 5ms/step
✅ 准确率: 0.6348, AUC: 0.6890, F1: 0.6921

============================================================
进度: 16/31

🔍 测试模型: epoch_016_loss_0.7175_acc_0.5289.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 11s 5ms/step
✅ 准确率: 0.5885, AUC: 0.6190, F1: 0.6762

============================================================
进度: 17/31

🔍 测试模型: epoch_017_loss_2.2195_acc_0.6281.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 11s 5ms/step
✅ 准确率: 0.6013, AUC: 0.6459, F1: 0.7251

============================================================
进度: 18/31

🔍 测试模型: epoch_018_loss_0.8726_acc_0.6281.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 15s 8ms/step
✅ 准确率: 0.6103, AUC: 0.6525, F1: 0.6834

============================================================
进度: 19/31

🔍 测试模型: epoch_019_loss_0.3739_acc_0.6322.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 18s 9ms/step
✅ 准确率: 0.6103, AUC: 0.6490, F1: 0.7175

============================================================
进度: 20/31

🔍 测试模型: epoch_020_loss_-0.0406_acc_0.5661.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 18s 9ms/step
✅ 准确率: 0.6284, AUC: 0.6635, F1: 0.6991

============================================================
进度: 21/31

🔍 测试模型: epoch_021_loss_0.1893_acc_0.6033.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 18s 9ms/step
✅ 准确率: 0.6002, AUC: 0.6211, F1: 0.6994

============================================================
进度: 22/31

🔍 测试模型: epoch_022_loss_0.6369_acc_0.6364.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 11s 6ms/step
✅ 准确率: 0.5805, AUC: 0.6005, F1: 0.7003

============================================================
进度: 23/31

🔍 测试模型: epoch_023_loss_2.6421_acc_0.6777.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 10s 5ms/step
✅ 准确率: 0.6103, AUC: 0.6349, F1: 0.7359

============================================================
进度: 24/31

🔍 测试模型: epoch_024_loss_-0.2147_acc_0.6281.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 13s 6ms/step
✅ 准确率: 0.6215, AUC: 0.6503, F1: 0.6965

============================================================
进度: 25/31

🔍 测试模型: epoch_025_loss_-0.0223_acc_0.6612.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 15s 7ms/step
✅ 准确率: 0.6061, AUC: 0.6187, F1: 0.7008

============================================================
进度: 26/31

🔍 测试模型: epoch_026_loss_0.5487_acc_0.5950.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 14s 7ms/step
✅ 准确率: 0.6135, AUC: 0.6252, F1: 0.7089

============================================================
进度: 27/31

🔍 测试模型: epoch_027_loss_1.9621_acc_0.6653.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 20s 10ms/step
✅ 准确率: 0.6162, AUC: 0.6471, F1: 0.7221

============================================================
进度: 28/31

🔍 测试模型: epoch_028_loss_1.9201_acc_0.6240.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 15s 7ms/step
✅ 准确率: 0.6066, AUC: 0.6454, F1: 0.7070

============================================================
进度: 29/31

🔍 测试模型: epoch_029_loss_3.1360_acc_0.6570.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 11s 5ms/step
✅ 准确率: 0.6061, AUC: 0.6269, F1: 0.7257

============================================================
进度: 30/31

🔍 测试模型: epoch_030_loss_2.1209_acc_0.6281.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 10s 5ms/step
✅ 准确率: 0.6199, AUC: 0.6472, F1: 0.7210

============================================================
进度: 31/31

🔍 测试模型: model.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 11s 5ms/step
✅ 准确率: 0.6199, AUC: 0.6472, F1: 0.7210

📊 结果已保存到: data/models/jaad/Transformer_depth/12Nov2025-06h37m17s/test_results_20251112_065655.csv
📝 报告已保存到: data/models/jaad/Transformer_depth/12Nov2025-06h37m17s/test_report_20251112_065655.txt

🏆 准确率最高的模型: epoch_004_loss_4.1657_acc_0.5909.h5 (准确率: 0.6863)
🗑️  开始清理epochs目录，将删除 30 个模型文件...
🗑️  已删除: epoch_025_loss_-0.0223_acc_0.6612.h5
🗑️  已删除: epoch_026_loss_0.5487_acc_0.5950.h5
🗑️  已删除: epoch_017_loss_2.2195_acc_0.6281.h5
🗑️  已删除: epoch_002_loss_6.3726_acc_0.5868.h5
🗑️  已删除: epoch_012_loss_2.4003_acc_0.7025.h5
📋 已将最佳模型复制到: data/models/jaad/Transformer_depth/12Nov2025-06h37m17s/epoch_004_loss_4.1657_acc_0.5909.h5
🗑️  已删除: epoch_004_loss_4.1657_acc_0.5909.h5
🗑️  已删除: epoch_009_loss_1.8818_acc_0.6240.h5
🗑️  已删除: epoch_023_loss_2.6421_acc_0.6777.h5
🗑️  已删除: epoch_003_loss_4.6296_acc_0.6653.h5
🗑️  已删除: epoch_024_loss_-0.2147_acc_0.6281.h5
🗑️  已删除: epoch_022_loss_0.6369_acc_0.6364.h5
🗑️  已删除: epoch_030_loss_2.1209_acc_0.6281.h5
🗑️  已删除: epoch_016_loss_0.7175_acc_0.5289.h5
🗑️  已删除: epoch_029_loss_3.1360_acc_0.6570.h5
🗑️  已删除: epoch_020_loss_-0.0406_acc_0.5661.h5
🗑️  已删除: epoch_027_loss_1.9621_acc_0.6653.h5
🗑️  已删除: epoch_001_loss_9.4281_acc_0.2769.h5
🗑️  已删除: epoch_011_loss_1.9681_acc_0.5248.h5
🗑️  已删除: epoch_014_loss_1.8917_acc_0.6405.h5
🗑️  已删除: epoch_005_loss_2.9923_acc_0.5331.h5
🗑️  已删除: epoch_021_loss_0.1893_acc_0.6033.h5
🗑️  已删除: epoch_006_loss_2.9230_acc_0.6653.h5
🗑️  已删除: epoch_008_loss_2.2916_acc_0.5496.h5
🗑️  已删除: epoch_010_loss_2.1210_acc_0.6116.h5
🗑️  已删除: epoch_007_loss_2.6105_acc_0.5992.h5
🗑️  已删除: epoch_019_loss_0.3739_acc_0.6322.h5
🗑️  已删除: epoch_013_loss_2.0122_acc_0.6570.h5
🗑️  已删除: epoch_028_loss_1.9201_acc_0.6240.h5
🗑️  已删除: epoch_018_loss_0.8726_acc_0.6281.h5
🗑️  已删除: epoch_015_loss_1.5134_acc_0.5744.h5
🗑️  已删除空的epochs目录
🔄 模型目录已重命名:
   原目录: 12Nov2025-06h37m17s
   新目录: 12Nov2025-06h37m17s_acc_0.6863

================================================================================
🎯 测试结果汇总
================================================================================
总模型数量: 31
成功测试: 31
失败测试: 0

📊 性能统计:
平均准确率: 0.6147 (±0.0496)
平均AUC: 0.6609 (±0.0322)
平均F1: 0.6844 (±0.1231)

🏆 最佳模型:
最高准确率: epoch_004_loss_4.1657_acc_0.5909.h5 (Acc: 0.6863)
最高AUC: epoch_002_loss_6.3726_acc_0.5868.h5 (AUC: 0.7317)
最高F1: epoch_004_loss_4.1657_acc_0.5909.h5 (F1: 0.7517)

✅ 测试完成 (耗时: 8.6 分钟)

================================================================================
🎉 训练和测试管道完成!
================================================================================
模型目录: data/models/jaad/Transformer_depth/12Nov2025-06h37m17s
总耗时: 19.7 分钟
结束时间: 2025-11-12 06:56:56
================================================================================
