 cd /home/minshi/Pedestrian_Crossing_Intention_Prediction ; /usr/bin/env /home/minshi/miniconda3/envs/tf26/bin/python /home/minshi/.vscode/extensions/ms-python.debugpy-2025.14.1-linux-x64/bundled/libs/debugpy/adapter/../../debugpy/launcher 54897 -- /home/minshi/Pedestrian_Crossing_Intention_Prediction/train_and_test_all_epoch_pipeline.py -c config_files/my/my_jaad.yaml 
================================================================================
🎯 训练和测试管道启动
================================================================================
配置文件: config_files/my/my_jaad.yaml
开始时间: 2025-11-12 05:57:47

🚀 开始训练...
2025-11-12 05:57:53.410169: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must
 be at least one NUMA node, so returning NUMA node zero                                                                                                             2025-11-12 05:57:53.416958: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must
 be at least one NUMA node, so returning NUMA node zero                                                                                                             2025-11-12 05:57:53.417192: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must
 be at least one NUMA node, so returning NUMA node zero                                                                                                             config_files/my/my_jaad.yaml
model_opts {'model': 'Transformer_depth', 'obs_input_type': ['box', 'depth', 'vehicle_speed', 'ped_speed'], 'enlarge_ratio': 1.5, 'obs_length': 16, 'time_to_event':
 [30, 60], 'overlap': 0.8, 'balance_data': False, 'apply_class_weights': True, 'dataset': 'jaad', 'normalize_boxes': True, 'generator': True, 'fusion_point': 'early', 'fusion_method': 'sum'}                                                                                                                                          data_opts {'fstride': 1, 'sample_type': 'beh', 'subset': 'default', 'data_split_type': 'default', 'seq_type': 'crossing', 'min_track_size': 76}
net_opts {'num_hidden_units': 256, 'global_pooling': 'avg', 'regularizer_val': 0.0001, 'cell_type': 'gru', 'backbone': 'vgg16', 'dropout': 0.1}
train_opts {'batch_size': 2, 'epochs': 30, 'lr': 5e-05, 'learning_scheduler': {}}
---------------------------------------------------------
Generating action sequence data
fstride: 1
sample_type: beh
subset: default
height_rng: [0, inf]
squarify_ratio: 0
data_split_type: default
seq_type: crossing
min_track_size: 76
random_params: {'ratios': None, 'val_data': True, 'regen_data': False}
kfold_params: {'num_folds': 5, 'fold': 1}
---------------------------------------------------------
Generating database for jaad
jaad database loaded from /home/minshi/Pedestrian_Crossing_Intention_Prediction/JAAD/data_cache/jaad_database.pkl
---------------------------------------------------------
Generating crossing data
Split: train
Number of pedestrians: 324 
Total number of samples: 194 
---------------------------------------------------------
Generating action sequence data
fstride: 1
sample_type: beh
subset: default
height_rng: [0, inf]
squarify_ratio: 0
data_split_type: default
seq_type: crossing
min_track_size: 76
random_params: {'ratios': None, 'val_data': True, 'regen_data': False}
kfold_params: {'num_folds': 5, 'fold': 1}
---------------------------------------------------------
Generating database for jaad
jaad database loaded from /home/minshi/Pedestrian_Crossing_Intention_Prediction/JAAD/data_cache/jaad_database.pkl
---------------------------------------------------------
Generating crossing data
Split: val
Number of pedestrians: 48 
Total number of samples: 22 
---------------------------------------------------------
Generating action sequence data
fstride: 1
sample_type: beh
subset: default
height_rng: [0, inf]
squarify_ratio: 0
data_split_type: default
seq_type: crossing
min_track_size: 76
random_params: {'ratios': None, 'val_data': True, 'regen_data': False}
kfold_params: {'num_folds': 5, 'fold': 1}
---------------------------------------------------------
Generating database for jaad
jaad database loaded from /home/minshi/Pedestrian_Crossing_Intention_Prediction/JAAD/data_cache/jaad_database.pkl
---------------------------------------------------------
Generating crossing data
Split: test
Number of pedestrians: 276 
Total number of samples: 171 
[DataGenerator] auto class_weight -> {0: 0.8247422680412371, 1: 0.17525773195876287}
[DataGenerator] auto class_weight -> {0: 0.7272727272727273, 1: 0.2727272727272727}
2025-11-12 05:57:56.987427: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN
) to use the following CPU instructions in performance-critical operations:  AVX2 FMA                                                                               To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12 05:57:56.989207: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must
 be at least one NUMA node, so returning NUMA node zero                                                                                                             2025-11-12 05:57:56.989427: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must
 be at least one NUMA node, so returning NUMA node zero                                                                                                             2025-11-12 05:57:56.989555: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must
 be at least one NUMA node, so returning NUMA node zero                                                                                                             2025-11-12 05:57:57.531657: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must
 be at least one NUMA node, so returning NUMA node zero                                                                                                             2025-11-12 05:57:57.531872: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must
 be at least one NUMA node, so returning NUMA node zero                                                                                                             2025-11-12 05:57:57.532011: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must
 be at least one NUMA node, so returning NUMA node zero                                                                                                             2025-11-12 05:57:57.532143: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3826 MB memory
:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9                                                        
============================================================
📊 MODEL PARAMETER STATISTICS
============================================================
Total parameters:        2,968,717
Trainable parameters:    2,968,711
Non-trainable parameters: 6
============================================================

/home/minshi/miniconda3/envs/tf26/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_ra
te` instead.                                                                                                                                                          warnings.warn(

🚀 Training started!
📁 Models will be saved to: data/models/jaad/Transformer_depth/12Nov2025-05h57m56s
📋 已复制 action_predict.py 到模型目录
2025-11-12 05:58:00.126795: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/30
2025-11-12 05:58:08.795710: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged
 once.                                                                                                                                                              2025-11-12 05:58:09.421169: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8100
1067/1067 [==============================] - 33s 22ms/step - loss: 9.8110 - cls_loss: 0.2088 - reg_loss: 0.0154 - intention_accuracy: 0.5412 - val_loss: 5.3492 - va
l_cls_loss: 0.2709 - val_reg_loss: 0.0034 - val_intention_accuracy: 0.4752                                                                                          /home/minshi/miniconda3/envs/tf26/lib/python3.8/site-packages/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must over
ride get_config. When loading, the custom mask layer must be passed to the custom_objects argument.                                                                   warnings.warn('Custom mask layers require a config and must override '
[Sigma] Epoch 1: sigma_cls=1.4614 sigma_reg=2.8319
Epoch 2/30
1067/1067 [==============================] - 12s 11ms/step - loss: 3.6602 - cls_loss: 0.1778 - reg_loss: 0.0048 - intention_accuracy: 0.6284 - val_loss: 2.7060 - va
l_cls_loss: 0.2818 - val_reg_loss: 0.0031 - val_intention_accuracy: 0.5579                                                                                          [Sigma] Epoch 2: sigma_cls=1.4073 sigma_reg=2.7780
Epoch 3/30
1067/1067 [==============================] - 11s 11ms/step - loss: 2.2437 - cls_loss: 0.1658 - reg_loss: 0.0034 - intention_accuracy: 0.6415 - val_loss: 2.0317 - va
l_cls_loss: 0.2991 - val_reg_loss: 0.0040 - val_intention_accuracy: 0.6322                                                                                          [Sigma] Epoch 3: sigma_cls=1.3534 sigma_reg=2.7238
Epoch 4/30
1067/1067 [==============================] - 12s 11ms/step - loss: 1.7874 - cls_loss: 0.1558 - reg_loss: 0.0037 - intention_accuracy: 0.6743 - val_loss: 1.7254 - va
l_cls_loss: 0.2796 - val_reg_loss: 0.0045 - val_intention_accuracy: 0.5992                                                                                          [Sigma] Epoch 4: sigma_cls=1.2997 sigma_reg=2.6696
Epoch 5/30
1067/1067 [==============================] - 13s 12ms/step - loss: 1.5540 - cls_loss: 0.1495 - reg_loss: 0.0037 - intention_accuracy: 0.6912 - val_loss: 1.5675 - va
l_cls_loss: 0.2956 - val_reg_loss: 0.0047 - val_intention_accuracy: 0.5620                                                                                          [Sigma] Epoch 5: sigma_cls=1.2462 sigma_reg=2.6154
Epoch 6/30
1067/1067 [==============================] - 16s 15ms/step - loss: 1.4094 - cls_loss: 0.1454 - reg_loss: 0.0036 - intention_accuracy: 0.7010 - val_loss: 1.5193 - va
l_cls_loss: 0.3797 - val_reg_loss: 0.0046 - val_intention_accuracy: 0.5661                                                                                          [Sigma] Epoch 6: sigma_cls=1.1930 sigma_reg=2.5610
Epoch 7/30
1067/1067 [==============================] - 23s 22ms/step - loss: 1.3044 - cls_loss: 0.1400 - reg_loss: 0.0035 - intention_accuracy: 0.6963 - val_loss: 1.4156 - va
l_cls_loss: 0.3413 - val_reg_loss: 0.0032 - val_intention_accuracy: 0.6074                                                                                          [Sigma] Epoch 7: sigma_cls=1.1400 sigma_reg=2.5065
Epoch 8/30
1067/1067 [==============================] - 24s 23ms/step - loss: 1.2187 - cls_loss: 0.1370 - reg_loss: 0.0034 - intention_accuracy: 0.7231 - val_loss: 1.4016 - va
l_cls_loss: 0.3981 - val_reg_loss: 0.0039 - val_intention_accuracy: 0.5785                                                                                          [Sigma] Epoch 8: sigma_cls=1.0878 sigma_reg=2.4521
Epoch 9/30
1067/1067 [==============================] - 24s 23ms/step - loss: 1.1349 - cls_loss: 0.1273 - reg_loss: 0.0033 - intention_accuracy: 0.7188 - val_loss: 1.3371 - va
l_cls_loss: 0.3828 - val_reg_loss: 0.0043 - val_intention_accuracy: 0.5909                                                                                          [Sigma] Epoch 9: sigma_cls=1.0357 sigma_reg=2.3976
Epoch 10/30
1067/1067 [==============================] - 25s 23ms/step - loss: 1.0548 - cls_loss: 0.1195 - reg_loss: 0.0033 - intention_accuracy: 0.7460 - val_loss: 1.3820 - va
l_cls_loss: 0.4712 - val_reg_loss: 0.0028 - val_intention_accuracy: 0.6322                                                                                          [Sigma] Epoch 10: sigma_cls=0.9839 sigma_reg=2.3432
Epoch 11/30
1067/1067 [==============================] - 24s 22ms/step - loss: 0.9796 - cls_loss: 0.1152 - reg_loss: 0.0034 - intention_accuracy: 0.7573 - val_loss: 1.2757 - va
l_cls_loss: 0.4035 - val_reg_loss: 0.0038 - val_intention_accuracy: 0.5868                                                                                          [Sigma] Epoch 11: sigma_cls=0.9324 sigma_reg=2.2888
Epoch 12/30
1067/1067 [==============================] - 23s 22ms/step - loss: 0.9005 - cls_loss: 0.1081 - reg_loss: 0.0031 - intention_accuracy: 0.7901 - val_loss: 1.3233 - va
l_cls_loss: 0.4635 - val_reg_loss: 0.0032 - val_intention_accuracy: 0.6488                                                                                          [Sigma] Epoch 12: sigma_cls=0.8819 sigma_reg=2.2343
Epoch 13/30
1067/1067 [==============================] - 24s 22ms/step - loss: 0.8234 - cls_loss: 0.1028 - reg_loss: 0.0030 - intention_accuracy: 0.8013 - val_loss: 1.2070 - va
l_cls_loss: 0.3927 - val_reg_loss: 0.0036 - val_intention_accuracy: 0.6901                                                                                          [Sigma] Epoch 13: sigma_cls=0.8327 sigma_reg=2.1799
Epoch 14/30
1067/1067 [==============================] - 23s 22ms/step - loss: 0.7360 - cls_loss: 0.0911 - reg_loss: 0.0030 - intention_accuracy: 0.8318 - val_loss: 1.1744 - va
l_cls_loss: 0.3803 - val_reg_loss: 0.0044 - val_intention_accuracy: 0.6322                                                                                          [Sigma] Epoch 14: sigma_cls=0.7838 sigma_reg=2.1254
Epoch 15/30
1067/1067 [==============================] - 23s 22ms/step - loss: 0.6706 - cls_loss: 0.0935 - reg_loss: 0.0029 - intention_accuracy: 0.8304 - val_loss: 1.3216 - va
l_cls_loss: 0.4672 - val_reg_loss: 0.0042 - val_intention_accuracy: 0.6694                                                                                          [Sigma] Epoch 15: sigma_cls=0.7376 sigma_reg=2.0707
Epoch 16/30
1067/1067 [==============================] - 24s 22ms/step - loss: 0.5924 - cls_loss: 0.0897 - reg_loss: 0.0027 - intention_accuracy: 0.8322 - val_loss: 1.3396 - va
l_cls_loss: 0.4652 - val_reg_loss: 0.0043 - val_intention_accuracy: 0.6488                                                                                          [Sigma] Epoch 16: sigma_cls=0.6937 sigma_reg=2.0160
Epoch 17/30
1067/1067 [==============================] - 23s 21ms/step - loss: 0.5125 - cls_loss: 0.0837 - reg_loss: 0.0026 - intention_accuracy: 0.8505 - val_loss: 1.9125 - va
l_cls_loss: 0.6931 - val_reg_loss: 0.0036 - val_intention_accuracy: 0.5826                                                                                          [Sigma] Epoch 17: sigma_cls=0.6518 sigma_reg=1.9613
Epoch 18/30
1067/1067 [==============================] - 23s 22ms/step - loss: 0.4444 - cls_loss: 0.0831 - reg_loss: 0.0026 - intention_accuracy: 0.8524 - val_loss: 1.5814 - va
l_cls_loss: 0.5229 - val_reg_loss: 0.0034 - val_intention_accuracy: 0.6364                                                                                          [Sigma] Epoch 18: sigma_cls=0.6137 sigma_reg=1.9066
Epoch 19/30
1067/1067 [==============================] - 23s 22ms/step - loss: 0.3752 - cls_loss: 0.0809 - reg_loss: 0.0025 - intention_accuracy: 0.8454 - val_loss: 1.7897 - va
l_cls_loss: 0.5663 - val_reg_loss: 0.0025 - val_intention_accuracy: 0.7107                                                                                          [Sigma] Epoch 19: sigma_cls=0.5796 sigma_reg=1.8519
Epoch 20/30
1067/1067 [==============================] - 24s 22ms/step - loss: 0.3082 - cls_loss: 0.0786 - reg_loss: 0.0025 - intention_accuracy: 0.8604 - val_loss: 2.0122 - va
l_cls_loss: 0.6009 - val_reg_loss: 0.0031 - val_intention_accuracy: 0.6529                                                                                          [Sigma] Epoch 20: sigma_cls=0.5490 sigma_reg=1.7971
Epoch 21/30
1067/1067 [==============================] - 23s 22ms/step - loss: 0.2365 - cls_loss: 0.0744 - reg_loss: 0.0024 - intention_accuracy: 0.8599 - val_loss: 2.0406 - va
l_cls_loss: 0.5725 - val_reg_loss: 0.0029 - val_intention_accuracy: 0.5826                                                                                          [Sigma] Epoch 21: sigma_cls=0.5216 sigma_reg=1.7423
Epoch 22/30
1067/1067 [==============================] - 23s 22ms/step - loss: 0.2126 - cls_loss: 0.0811 - reg_loss: 0.0024 - intention_accuracy: 0.8463 - val_loss: 1.9271 - va
l_cls_loss: 0.5194 - val_reg_loss: 0.0027 - val_intention_accuracy: 0.6901                                                                                          [Sigma] Epoch 22: sigma_cls=0.5022 sigma_reg=1.6874
Epoch 23/30
1067/1067 [==============================] - 23s 22ms/step - loss: 0.1073 - cls_loss: 0.0675 - reg_loss: 0.0023 - intention_accuracy: 0.8772 - val_loss: 2.4924 - va
l_cls_loss: 0.6236 - val_reg_loss: 0.0021 - val_intention_accuracy: 0.7066                                                                                          [Sigma] Epoch 23: sigma_cls=0.4801 sigma_reg=1.6325
Epoch 24/30
1067/1067 [==============================] - 24s 23ms/step - loss: 0.0923 - cls_loss: 0.0754 - reg_loss: 0.0023 - intention_accuracy: 0.8702 - val_loss: 2.3309 - va
l_cls_loss: 0.5670 - val_reg_loss: 0.0030 - val_intention_accuracy: 0.6777                                                                                          [Sigma] Epoch 24: sigma_cls=0.4665 sigma_reg=1.5776
Epoch 25/30
1067/1067 [==============================] - 25s 24ms/step - loss: 0.0098 - cls_loss: 0.0673 - reg_loss: 0.0023 - intention_accuracy: 0.8754 - val_loss: 2.8874 - va
l_cls_loss: 0.6563 - val_reg_loss: 0.0023 - val_intention_accuracy: 0.7314                                                                                          [Sigma] Epoch 25: sigma_cls=0.4507 sigma_reg=1.5225
Epoch 26/30
1067/1067 [==============================] - 26s 24ms/step - loss: -0.0102 - cls_loss: 0.0724 - reg_loss: 0.0022 - intention_accuracy: 0.8679 - val_loss: 3.1392 - v
al_cls_loss: 0.6835 - val_reg_loss: 0.0029 - val_intention_accuracy: 0.5992                                                                                         [Sigma] Epoch 26: sigma_cls=0.4389 sigma_reg=1.4675
Epoch 27/30
1067/1067 [==============================] - 24s 23ms/step - loss: -0.0996 - cls_loss: 0.0644 - reg_loss: 0.0021 - intention_accuracy: 0.8791 - val_loss: 2.6077 - v
al_cls_loss: 0.5584 - val_reg_loss: 0.0033 - val_intention_accuracy: 0.6694                                                                                         [Sigma] Epoch 27: sigma_cls=0.4253 sigma_reg=1.4123
Epoch 28/30
1067/1067 [==============================] - 24s 23ms/step - loss: -0.1584 - cls_loss: 0.0623 - reg_loss: 0.0021 - intention_accuracy: 0.8861 - val_loss: 3.1837 - v
al_cls_loss: 0.6365 - val_reg_loss: 0.0022 - val_intention_accuracy: 0.6983                                                                                         [Sigma] Epoch 28: sigma_cls=0.4129 sigma_reg=1.3571
Epoch 29/30
1067/1067 [==============================] - 25s 23ms/step - loss: -0.2117 - cls_loss: 0.0616 - reg_loss: 0.0021 - intention_accuracy: 0.8824 - val_loss: 4.2557 - v
al_cls_loss: 0.7880 - val_reg_loss: 0.0030 - val_intention_accuracy: 0.6736                                                                                         [Sigma] Epoch 29: sigma_cls=0.4021 sigma_reg=1.3018
Epoch 30/30
1067/1067 [==============================] - 24s 22ms/step - loss: -0.2266 - cls_loss: 0.0667 - reg_loss: 0.0021 - intention_accuracy: 0.8814 - val_loss: 4.0746 - v
al_cls_loss: 0.7440 - val_reg_loss: 0.0025 - val_intention_accuracy: 0.7066                                                                                         [Sigma] Epoch 30: sigma_cls=0.3958 sigma_reg=1.2464

🎯 Training completed!
📁 All epoch models saved in: data/models/jaad/Transformer_depth/12Nov2025-05h57m56s/epochs
Train model is saved to data/models/jaad/Transformer_depth/12Nov2025-05h57m56s/model.h5
Available metrics: ['loss', 'cls_loss', 'reg_loss', 'intention_accuracy', 'val_loss', 'val_cls_loss', 'val_reg_loss', 'val_intention_accuracy', 'sigma_cls', 'val_si
gma_cls', 'sigma_reg', 'val_sigma_reg']                                                                                                                             Training plots saved to model directory
Wrote configs to data/models/jaad/Transformer_depth/12Nov2025-05h57m56s/configs.yaml
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 20s 10ms/step

======================================================================
🎯 MODEL TEST RESULTS 🎯
======================================================================
Accuracy:   0.5917
AUC:        0.5225
F1-Score:   0.7098
Precision:  0.6392
Recall:     0.7978
======================================================================

Model saved to data/models/jaad/Transformer_depth/12Nov2025-05h57m56s/

✅ 训练完成 (耗时: 12.0 分钟)
🔍 查找最新模型目录...
📁 找到模型目录: data/models/jaad/Transformer_depth/12Nov2025-05h57m56s

🧪 开始测试模型...
2025-11-12 06:09:52.920959: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must
 be at least one NUMA node, so returning NUMA node zero                                                                                                             2025-11-12 06:09:52.927679: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must
 be at least one NUMA node, so returning NUMA node zero                                                                                                             2025-11-12 06:09:52.927888: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must
 be at least one NUMA node, so returning NUMA node zero                                                                                                             🚀 开始测试模型目录: data/models/jaad/Transformer_depth/12Nov2025-05h57m56s
✅ 配置文件加载成功
✅ 数据集初始化成功
🔄 生成测试数据...
---------------------------------------------------------
Generating action sequence data
fstride: 1
sample_type: beh
subset: default
height_rng: [0, inf]
squarify_ratio: 0
data_split_type: default
seq_type: crossing
min_track_size: 76
random_params: {'ratios': None, 'val_data': True, 'regen_data': False}
kfold_params: {'num_folds': 5, 'fold': 1}
---------------------------------------------------------
Generating database for jaad
jaad database loaded from /home/minshi/Pedestrian_Crossing_Intention_Prediction/JAAD/data_cache/jaad_database.pkl
---------------------------------------------------------
Generating crossing data
Split: test
Number of pedestrians: 276 
Total number of samples: 171 
✅ 测试数据生成完成
📁 找到 31 个模型文件

============================================================
进度: 1/31

🔍 测试模型: epoch_001_loss_5.3492_acc_0.4752.h5
2025-11-12 06:09:54.458909: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN
) to use the following CPU instructions in performance-critical operations:  AVX2 FMA                                                                               To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-12 06:09:54.461406: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must
 be at least one NUMA node, so returning NUMA node zero                                                                                                             2025-11-12 06:09:54.461624: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must
 be at least one NUMA node, so returning NUMA node zero                                                                                                             2025-11-12 06:09:54.461756: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must
 be at least one NUMA node, so returning NUMA node zero                                                                                                             2025-11-12 06:09:55.016475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must
 be at least one NUMA node, so returning NUMA node zero                                                                                                             2025-11-12 06:09:55.016680: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must
 be at least one NUMA node, so returning NUMA node zero                                                                                                             2025-11-12 06:09:55.016825: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must
 be at least one NUMA node, so returning NUMA node zero                                                                                                             2025-11-12 06:09:55.016954: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3468 MB memory
:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9                                                        [DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
2025-11-12 06:09:56.944955: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)
2025-11-12 06:09:58.942053: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged
 once.                                                                                                                                                              2025-11-12 06:09:59.559938: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8100
1881/1881 [==============================] - 21s 10ms/step
✅ 准确率: 0.5752, AUC: 0.7105, F1: 0.5554

============================================================
进度: 2/31

🔍 测试模型: epoch_002_loss_2.7060_acc_0.5579.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 20s 10ms/step
✅ 准确率: 0.6523, AUC: 0.7116, F1: 0.6769

============================================================
进度: 3/31

🔍 测试模型: epoch_003_loss_2.0317_acc_0.6322.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 20s 10ms/step
✅ 准确率: 0.6725, AUC: 0.7086, F1: 0.7448

============================================================
进度: 4/31

🔍 测试模型: epoch_004_loss_1.7254_acc_0.5992.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 20s 10ms/step
✅ 准确率: 0.6247, AUC: 0.6828, F1: 0.6505

============================================================
进度: 5/31

🔍 测试模型: epoch_005_loss_1.5675_acc_0.5620.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 20s 10ms/step
✅ 准确率: 0.6512, AUC: 0.7083, F1: 0.6800

============================================================
进度: 6/31

🔍 测试模型: epoch_006_loss_1.5193_acc_0.5661.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 20s 10ms/step
✅ 准确率: 0.6826, AUC: 0.7166, F1: 0.7414

============================================================
进度: 7/31

🔍 测试模型: epoch_007_loss_1.4156_acc_0.6074.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 21s 11ms/step
✅ 准确率: 0.6209, AUC: 0.6609, F1: 0.7331

============================================================
进度: 8/31

🔍 测试模型: epoch_008_loss_1.4016_acc_0.5785.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 19s 9ms/step
✅ 准确率: 0.6550, AUC: 0.7132, F1: 0.6914

============================================================
进度: 9/31

🔍 测试模型: epoch_009_loss_1.3371_acc_0.5909.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 19s 10ms/step
✅ 准确率: 0.6172, AUC: 0.6717, F1: 0.6768

============================================================
进度: 10/31

🔍 测试模型: epoch_010_loss_1.3820_acc_0.6322.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 17s 8ms/step
✅ 准确率: 0.6528, AUC: 0.6834, F1: 0.7428

============================================================
进度: 11/31

🔍 测试模型: epoch_011_loss_1.2757_acc_0.5868.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 11s 5ms/step
✅ 准确率: 0.5922, AUC: 0.6350, F1: 0.6543

============================================================
进度: 12/31

🔍 测试模型: epoch_012_loss_1.3233_acc_0.6488.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 10s 5ms/step
✅ 准确率: 0.6491, AUC: 0.6625, F1: 0.7227

============================================================
进度: 13/31

🔍 测试模型: epoch_013_loss_1.2070_acc_0.6901.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 11s 6ms/step
✅ 准确率: 0.6396, AUC: 0.6559, F1: 0.7201

============================================================
进度: 14/31

🔍 测试模型: epoch_014_loss_1.1744_acc_0.6322.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 13s 6ms/step
✅ 准确率: 0.5991, AUC: 0.6271, F1: 0.6996

============================================================
进度: 15/31

🔍 测试模型: epoch_015_loss_1.3216_acc_0.6694.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 18s 9ms/step
✅ 准确率: 0.5853, AUC: 0.6251, F1: 0.6922

============================================================
进度: 16/31

🔍 测试模型: epoch_016_loss_1.3396_acc_0.6488.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 19s 9ms/step
✅ 准确率: 0.5651, AUC: 0.5912, F1: 0.6645

============================================================
进度: 17/31

🔍 测试模型: epoch_017_loss_1.9125_acc_0.5826.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 20s 10ms/step
✅ 准确率: 0.6252, AUC: 0.6476, F1: 0.6983

============================================================
进度: 18/31

🔍 测试模型: epoch_018_loss_1.5814_acc_0.6364.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 19s 10ms/step
✅ 准确率: 0.6209, AUC: 0.6427, F1: 0.7091

============================================================
进度: 19/31

🔍 测试模型: epoch_019_loss_1.7897_acc_0.7107.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 12s 6ms/step
✅ 准确率: 0.6183, AUC: 0.6482, F1: 0.7153

============================================================
进度: 20/31

🔍 测试模型: epoch_020_loss_2.0122_acc_0.6529.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 12s 6ms/step
✅ 准确率: 0.6135, AUC: 0.6276, F1: 0.6923

============================================================
进度: 21/31

🔍 测试模型: epoch_021_loss_2.0406_acc_0.5826.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 14s 7ms/step
✅ 准确率: 0.6066, AUC: 0.6387, F1: 0.6840

============================================================
进度: 22/31

🔍 测试模型: epoch_022_loss_1.9271_acc_0.6901.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 19s 10ms/step
✅ 准确率: 0.6077, AUC: 0.6282, F1: 0.6960

============================================================
进度: 23/31

🔍 测试模型: epoch_023_loss_2.4924_acc_0.7066.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 19s 10ms/step
✅ 准确率: 0.6130, AUC: 0.6337, F1: 0.7174

============================================================
进度: 24/31

🔍 测试模型: epoch_024_loss_2.3309_acc_0.6777.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 20s 10ms/step
✅ 准确率: 0.5890, AUC: 0.6306, F1: 0.6965

============================================================
进度: 25/31

🔍 测试模型: epoch_025_loss_2.8874_acc_0.7314.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 20s 10ms/step
✅ 准确率: 0.5784, AUC: 0.6115, F1: 0.7013

============================================================
进度: 26/31

🔍 测试模型: epoch_026_loss_3.1392_acc_0.5992.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 19s 9ms/step
✅ 准确率: 0.6130, AUC: 0.6180, F1: 0.6832

============================================================
进度: 27/31

🔍 测试模型: epoch_027_loss_2.6077_acc_0.6694.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 20s 10ms/step
✅ 准确率: 0.5944, AUC: 0.6269, F1: 0.7035

============================================================
进度: 28/31

🔍 测试模型: epoch_028_loss_3.1837_acc_0.6983.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 17s 9ms/step
✅ 准确率: 0.6130, AUC: 0.6290, F1: 0.7086

============================================================
进度: 29/31

🔍 测试模型: epoch_029_loss_4.2557_acc_0.6736.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 11s 6ms/step
✅ 准确率: 0.6183, AUC: 0.6551, F1: 0.7130

============================================================
进度: 30/31

🔍 测试模型: epoch_030_loss_4.0746_acc_0.7066.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 12s 6ms/step
✅ 准确率: 0.5917, AUC: 0.6247, F1: 0.7098

============================================================
进度: 31/31

🔍 测试模型: model.h5
[DataGenerator] auto class_weight -> {0: 0.6257309941520468, 1: 0.3742690058479532}
1881/1881 [==============================] - 16s 8ms/step
✅ 准确率: 0.5917, AUC: 0.6247, F1: 0.7098

📊 结果已保存到: data/models/jaad/Transformer_depth/12Nov2025-05h57m56s/test_results_20251112_061939.csv
📝 报告已保存到: data/models/jaad/Transformer_depth/12Nov2025-05h57m56s/test_report_20251112_061939.txt

🏆 准确率最高的模型: epoch_006_loss_1.5193_acc_0.5661.h5 (准确率: 0.6826)
🗑️  开始清理epochs目录，将删除 30 个模型文件...
🗑️  已删除: epoch_024_loss_2.3309_acc_0.6777.h5
🗑️  已删除: epoch_014_loss_1.1744_acc_0.6322.h5
🗑️  已删除: epoch_020_loss_2.0122_acc_0.6529.h5
🗑️  已删除: epoch_018_loss_1.5814_acc_0.6364.h5
🗑️  已删除: epoch_002_loss_2.7060_acc_0.5579.h5
🗑️  已删除: epoch_009_loss_1.3371_acc_0.5909.h5
🗑️  已删除: epoch_005_loss_1.5675_acc_0.5620.h5
🗑️  已删除: epoch_013_loss_1.2070_acc_0.6901.h5
🗑️  已删除: epoch_010_loss_1.3820_acc_0.6322.h5
🗑️  已删除: epoch_026_loss_3.1392_acc_0.5992.h5
🗑️  已删除: epoch_022_loss_1.9271_acc_0.6901.h5
🗑️  已删除: epoch_017_loss_1.9125_acc_0.5826.h5
🗑️  已删除: epoch_027_loss_2.6077_acc_0.6694.h5
🗑️  已删除: epoch_011_loss_1.2757_acc_0.5868.h5
🗑️  已删除: epoch_019_loss_1.7897_acc_0.7107.h5
🗑️  已删除: epoch_003_loss_2.0317_acc_0.6322.h5
🗑️  已删除: epoch_001_loss_5.3492_acc_0.4752.h5
🗑️  已删除: epoch_012_loss_1.3233_acc_0.6488.h5
📋 已将最佳模型复制到: data/models/jaad/Transformer_depth/12Nov2025-05h57m56s/epoch_006_loss_1.5193_acc_0.5661.h5
🗑️  已删除: epoch_006_loss_1.5193_acc_0.5661.h5
🗑️  已删除: epoch_029_loss_4.2557_acc_0.6736.h5
🗑️  已删除: epoch_015_loss_1.3216_acc_0.6694.h5
🗑️  已删除: epoch_025_loss_2.8874_acc_0.7314.h5
🗑️  已删除: epoch_028_loss_3.1837_acc_0.6983.h5
🗑️  已删除: epoch_030_loss_4.0746_acc_0.7066.h5
🗑️  已删除: epoch_008_loss_1.4016_acc_0.5785.h5
🗑️  已删除: epoch_007_loss_1.4156_acc_0.6074.h5
🗑️  已删除: epoch_021_loss_2.0406_acc_0.5826.h5
🗑️  已删除: epoch_004_loss_1.7254_acc_0.5992.h5
🗑️  已删除: epoch_016_loss_1.3396_acc_0.6488.h5
🗑️  已删除: epoch_023_loss_2.4924_acc_0.7066.h5
🗑️  已删除空的epochs目录
🔄 模型目录已重命名:
   原目录: 12Nov2025-05h57m56s
   新目录: 12Nov2025-05h57m56s_acc_0.6826

================================================================================
🎯 测试结果汇总
================================================================================
总模型数量: 31
成功测试: 31
失败测试: 0

📊 性能统计:
平均准确率: 0.6171 (±0.0288)
平均AUC: 0.6533 (±0.0350)
平均F1: 0.6963 (±0.0352)

🏆 最佳模型:
最高准确率: epoch_006_loss_1.5193_acc_0.5661.h5 (Acc: 0.6826)
最高AUC: epoch_006_loss_1.5193_acc_0.5661.h5 (AUC: 0.7166)
最高F1: epoch_003_loss_2.0317_acc_0.6322.h5 (F1: 0.7448)

✅ 测试完成 (耗时: 9.9 分钟)

================================================================================
🎉 训练和测试管道完成!
================================================================================
模型目录: data/models/jaad/Transformer_depth/12Nov2025-05h57m56s
总耗时: 21.9 分钟
结束时间: 2025-11-12 06:19:40
================================================================================
